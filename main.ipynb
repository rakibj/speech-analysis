{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "558032e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import whisper\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5177df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "pd.set_option(\"display.width\", 0)\n",
    "load_dotenv()\n",
    "audio_file_path = \"sample7.flac\"\n",
    "speech_context = \"conversational\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "085294c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = whisper.load_model(\"base\", device=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "adfb1d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# result = model.transcribe(\n",
    "#     audio_file_path,\n",
    "#     task=\"transcribe\",\n",
    "#     temperature=0,\n",
    "#     word_timestamps=True,\n",
    "#     condition_on_previous_text=False,\n",
    "#     initial_prompt=(\n",
    "#         \"Transcribe verbatim. Include filler words like um, uh, er, \"\n",
    "#         \"false starts, repetitions, and hesitations.\"\n",
    "#     ),\n",
    "#     fp16=False,\n",
    "# )\n",
    "\n",
    "result = model.transcribe(\n",
    "    audio_file_path,\n",
    "    task=\"transcribe\",\n",
    "    word_timestamps=True,\n",
    "    fp16=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "8386e43a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>duration</th>\n",
       "      <th>confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>She</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.745907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>poured</td>\n",
       "      <td>0.94</td>\n",
       "      <td>1.20</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.989556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>concrete</td>\n",
       "      <td>1.20</td>\n",
       "      <td>1.84</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.999496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>straight</td>\n",
       "      <td>1.84</td>\n",
       "      <td>2.32</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.974266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>into</td>\n",
       "      <td>2.32</td>\n",
       "      <td>2.74</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.968895</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       word  start   end  duration  confidence\n",
       "0       She   0.00  0.94      0.94    0.745907\n",
       "1    poured   0.94  1.20      0.26    0.989556\n",
       "2  concrete   1.20  1.84      0.64    0.999496\n",
       "3  straight   1.84  2.32      0.48    0.974266\n",
       "4      into   2.32  2.74      0.42    0.968895"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = []\n",
    "for seg in result[\"segments\"]:\n",
    "    for w in seg[\"words\"]:\n",
    "        words.append({\n",
    "            \"word\": w[\"word\"].strip(),\n",
    "            \"start\": float(w[\"start\"]),\n",
    "            \"end\": float(w[\"end\"]),\n",
    "            \"duration\": float(w[\"end\"] - w[\"start\"]),\n",
    "            \"confidence\": float(w[\"probability\"])\n",
    "        })\n",
    "\n",
    "df_words = pd.DataFrame(words)\n",
    "df_words.sort_values(\"confidence\").head(5)\n",
    "df_words.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "585101d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                text  \\\n",
      "0       She poured concrete straight into the storm pipe at the edge of her yard, and the wet cement   \n",
      "1                                  hardened inside, sealing the pipe so water couldn't flow through.   \n",
      "2  You see, that pipe was part of the neighborhood's draining system, carrying rainwater underground   \n",
      "3                                                           to a nearby pond where it could collect.   \n",
      "4            But the woman claimed that the drain was eating away at her yard and causing sinkholes.   \n",
      "\n",
      "   start    end  duration  avg_word_confidence  \n",
      "0   0.00   6.16      6.16             0.954545  \n",
      "1   6.16  10.76      4.60             0.971571  \n",
      "2  11.12  17.04      5.92             0.977924  \n",
      "3  17.04  19.64      2.60             0.990735  \n",
      "4  20.08  25.32      5.24             0.977607  \n"
     ]
    }
   ],
   "source": [
    "segments = []\n",
    "for seg in result[\"segments\"]:\n",
    "    segments.append({\n",
    "        \"text\": seg[\"text\"].strip(),\n",
    "        \"start\": float(seg[\"start\"]),\n",
    "        \"end\": float(seg[\"end\"]),\n",
    "        \"duration\": float(float(seg[\"end\"]) - float(seg[\"start\"])),\n",
    "        \"avg_word_confidence\": sum([float(w[\"probability\"]) for w in seg[\"words\"]]) / (len(seg[\"words\"]) if len(seg[\"words\"]) > 0 else 0.0)\n",
    "    })\n",
    "\n",
    "df_segments = pd.DataFrame(segments)\n",
    "with pd.option_context('display.max_colwidth', None):\n",
    "    print(df_segments.head()) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd0ba46",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "6ee5d112",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total duration (s): 31.26\n",
      "Number of words: 83\n",
      "Words per minute: 159.31\n"
     ]
    }
   ],
   "source": [
    "total_duration = float(df_segments.iloc[-1]['end']) #- df_segments.iloc[0]['start'])\n",
    "words_per_minute = (len(df_words) * 60) / (total_duration) \n",
    "\n",
    "print(f\"Total duration (s): {total_duration:.2f}\")\n",
    "print(f\"Number of words: {len(df_words)}\")\n",
    "print(f\"Words per minute: {words_per_minute:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "61da4617",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "       0.  , 0.  , 0.28, 0.  , 0.  , 0.  , 0.  , 0.  , 0.56, 0.  , 0.  ,\n",
       "       0.  , 0.  , 0.  , 0.  , 0.  , 0.36, 0.  , 0.24, 0.  , 0.  , 0.  ,\n",
       "       0.  , 0.  , 0.  , 0.  , 0.  , 0.26, 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "       0.  , 0.  , 0.  , 0.  , 0.  , 0.44, 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "       0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "       0.  , 0.  , 0.  , 0.  , 0.26, 0.  , 0.  , 0.  , 0.  , 0.  , 0.34,\n",
       "       0.28, 0.  , 0.  , 0.  , 0.  ])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pauses = df_words[\"start\"].iloc[1:].values - df_words[\"end\"].iloc[:-1].values\n",
    "long_pauses = pauses[pauses > 1.0]\n",
    "very_long_pauses = pauses[pauses > 2.0]\n",
    "pauses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "f60af679",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total words: 83\n",
      "Unique words: 61\n",
      "Vocabulary richness: 0.73\n"
     ]
    }
   ],
   "source": [
    "words_clean = df_words['word'].str.lower()\n",
    "words_unique = words_clean.nunique()\n",
    "words_total = len(words_clean)\n",
    "vocab_richness = words_unique / words_total if words_total > 0 else 0\n",
    "top_repeats = words_clean.value_counts().head(5)\n",
    "print(f\"Total words: {words_total}\")\n",
    "print(f\"Unique words: {words_unique}\")\n",
    "print(f\"Vocabulary richness: {vocab_richness:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "c6f866e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-large-960h and are newly initialized: ['wav2vec2.masked_spec_embed']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "from transformers import Wav2Vec2Processor, Wav2Vec2ForCTC\n",
    "import soundfile as sf\n",
    "\n",
    "processor = Wav2Vec2Processor.from_pretrained(\"facebook/wav2vec2-large-960h\") #Audio → numbers → shape the model expects\n",
    "wav2vec = Wav2Vec2ForCTC.from_pretrained(\"facebook/wav2vec2-large-960h\") #The model itself\n",
    "wav2vec.eval(); #Set to eval mode (we are not training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "439bcff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "waveform, sr = sf.read(audio_file_path, dtype=\"float32\") # waveform: np.ndarray, sr: int, each number in waveform signifies amplitude at that time\n",
    "\n",
    "# Convert stereo → mono\n",
    "if waveform.ndim == 2:\n",
    "    waveform = waveform.mean(axis=1)\n",
    "\n",
    "waveform = torch.from_numpy(waveform) # Convert to torch tensor\n",
    "\n",
    "# Resample to 16kHz if needed (since the model expects 16kHz audio)\n",
    "if sr != 16000:\n",
    "    waveform = torchaudio.functional.resample(waveform, sr, 16000)\n",
    "    sr = 16000\n",
    "\n",
    "# Prepare input for the model\n",
    "inputs = processor(\n",
    "    waveform.squeeze(), # Remove any extra dimensions\n",
    "    sampling_rate=16000,\n",
    "    return_tensors=\"pt\", # Return PyTorch tensors\n",
    ")\n",
    "\n",
    "# Forward pass through the model\n",
    "with torch.no_grad():\n",
    "    logits = wav2vec(**inputs).logits # logit = time_step_1 -> [prob_sound_1, ...]\n",
    "\n",
    "# for each time slice, choose sound with highest probability\n",
    "predicted_ids = torch.argmax(logits, dim=-1)[0]\n",
    "# Convert token IDs to human readable tokens\n",
    "tokens = processor.tokenizer.convert_ids_to_tokens(predicted_ids.tolist())\n",
    "#tokens # each token is 20ms of audio that represents what was spoken\n",
    "# <pad> = nothing meaningful happened in this 20ms slice\n",
    "# | = word boundary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "a91ef802",
   "metadata": {},
   "outputs": [],
   "source": [
    "FRAME_SEC = 0.02  # 20 ms per token\n",
    "\n",
    "events = []\n",
    "current = None\n",
    "\n",
    "for i, tok in enumerate(tokens):\n",
    "    t = i * FRAME_SEC\n",
    "\n",
    "    if tok == '<pad>':\n",
    "        if current:\n",
    "            current[\"end\"] = t\n",
    "            events.append(current)\n",
    "            current = None\n",
    "        continue\n",
    "\n",
    "    if current and current[\"label\"] == tok:\n",
    "        # same sound continuing (elongation)\n",
    "        continue\n",
    "\n",
    "    if current:\n",
    "        current[\"end\"] = t\n",
    "        events.append(current)\n",
    "\n",
    "    current = {\n",
    "        \"label\": tok,\n",
    "        \"start\": t\n",
    "    }\n",
    "\n",
    "if current:\n",
    "    current[\"end\"] = t\n",
    "    events.append(current)\n",
    "\n",
    "events;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "c21cce3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>POURED</td>\n",
       "      <td>1.04</td>\n",
       "      <td>1.28</td>\n",
       "      <td>0.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CON</td>\n",
       "      <td>1.42</td>\n",
       "      <td>1.58</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CRE</td>\n",
       "      <td>1.70</td>\n",
       "      <td>1.82</td>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>STRAIGHT</td>\n",
       "      <td>2.14</td>\n",
       "      <td>2.48</td>\n",
       "      <td>0.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>STORM</td>\n",
       "      <td>3.06</td>\n",
       "      <td>3.38</td>\n",
       "      <td>0.32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     labels  start   end  duration\n",
       "0    POURED   1.04  1.28      0.24\n",
       "1       CON   1.42  1.58      0.16\n",
       "2       CRE   1.70  1.82      0.12\n",
       "3  STRAIGHT   2.14  2.48      0.34\n",
       "4     STORM   3.06  3.38      0.32"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MIN_GAP = 0.06       # 60 ms\n",
    "MIN_EVENT = 0.12     # 120 ms\n",
    "\n",
    "merged = []\n",
    "current = None\n",
    "\n",
    "for e in events:\n",
    "    label = e[\"label\"]\n",
    "\n",
    "    # hard boundary: word separator\n",
    "    if label == \"|\":\n",
    "        if current:\n",
    "            current[\"end\"] = e[\"start\"]\n",
    "            if current[\"end\"] - current[\"start\"] >= MIN_EVENT:\n",
    "                merged.append(current)\n",
    "            current = None\n",
    "        continue\n",
    "\n",
    "    if current is None:\n",
    "        current = {\n",
    "            \"labels\": [label],\n",
    "            \"start\": e[\"start\"],\n",
    "            \"end\": e[\"end\"]\n",
    "        }\n",
    "        continue\n",
    "\n",
    "    gap = e[\"start\"] - current[\"end\"]\n",
    "\n",
    "    if gap <= MIN_GAP:\n",
    "        # same acoustic blob\n",
    "        current[\"labels\"].append(label)\n",
    "        current[\"end\"] = e[\"end\"]\n",
    "    else:\n",
    "        # close previous blob\n",
    "        if current[\"end\"] - current[\"start\"] >= MIN_EVENT:\n",
    "            merged.append(current)\n",
    "        current = {\n",
    "            \"labels\": [label],\n",
    "            \"start\": e[\"start\"],\n",
    "            \"end\": e[\"end\"]\n",
    "        }\n",
    "\n",
    "# flush last\n",
    "if current and (current[\"end\"] - current[\"start\"] >= MIN_EVENT):\n",
    "    merged.append(current)\n",
    "\n",
    "df_wav2vec_merged = pd.DataFrame([\n",
    "    {\n",
    "        \"labels\": \"\".join(m[\"labels\"]),\n",
    "        \"start\": m[\"start\"],\n",
    "        \"end\": m[\"end\"],\n",
    "        \"duration\": m[\"end\"] - m[\"start\"]\n",
    "    }\n",
    "    for m in merged\n",
    "])\n",
    "\n",
    "df_wav2vec_merged.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "331efb62",
   "metadata": {},
   "outputs": [],
   "source": [
    "pauses = []\n",
    "\n",
    "for i in range(1, len(events)):\n",
    "    gap = events[i][\"start\"] - events[i-1][\"end\"]\n",
    "    if gap >= 0.3:  # 300 ms\n",
    "        pauses.append({\n",
    "            \"type\": \"pause\",\n",
    "            \"start\": events[i-1][\"end\"],\n",
    "            \"end\": events[i][\"start\"],\n",
    "            \"duration\": gap\n",
    "        })\n",
    "\n",
    "pauses;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "9ead1ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import soundfile as sf\n",
    "import torchaudio\n",
    "\n",
    "def load_audio(path):\n",
    "    audio, sr = sf.read(path, dtype=\"float32\")\n",
    "    if audio.ndim == 2:\n",
    "        audio = audio.mean(axis=1)  # stereo → mono\n",
    "    if sr != 16000:\n",
    "        audio = torchaudio.functional.resample(\n",
    "            torch.from_numpy(audio), sr, 16000\n",
    "        ).numpy()\n",
    "        sr = 16000\n",
    "    return audio, sr\n",
    "\n",
    "audio, sr = load_audio(audio_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "d67c1a4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>she</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>poured</td>\n",
       "      <td>1.047</td>\n",
       "      <td>1.308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>concrete</td>\n",
       "      <td>1.409</td>\n",
       "      <td>2.013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>straight</td>\n",
       "      <td>2.174</td>\n",
       "      <td>2.496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>into</td>\n",
       "      <td>2.637</td>\n",
       "      <td>2.919</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       word  start    end\n",
       "0       she  0.000  0.966\n",
       "1    poured  1.047  1.308\n",
       "2  concrete  1.409  2.013\n",
       "3  straight  2.174  2.496\n",
       "4      into  2.637  2.919"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import whisperx\n",
    "import torch\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "align_model, metadata = whisperx.load_align_model(\n",
    "    language_code=\"en\",  # or result[\"language\"] if available\n",
    "    device=device\n",
    ")\n",
    "\n",
    "aligned = whisperx.align(\n",
    "    result[\"segments\"],  # <-- your existing Whisper output\n",
    "    align_model,\n",
    "    metadata,\n",
    "    audio,\n",
    "    device\n",
    ")\n",
    "\n",
    "aligned_words = []\n",
    "\n",
    "for seg in aligned[\"segments\"]:\n",
    "    for w in seg.get(\"words\", []):\n",
    "        if w[\"start\"] is not None and w[\"end\"] is not None:\n",
    "            aligned_words.append({\n",
    "                \"word\": w[\"word\"].strip().lower(),\n",
    "                \"start\": float(w[\"start\"]),\n",
    "                \"end\": float(w[\"end\"])\n",
    "            })\n",
    "\n",
    "df_aligned_words = pd.DataFrame(aligned_words)\n",
    "df_aligned_words = df_aligned_words.sort_values(\"start\").reset_index(drop=True)\n",
    "df_aligned_words.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "896c512f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>duration</th>\n",
       "      <th>overlaps_word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [labels, start, end, duration, overlaps_word]\n",
       "Index: []"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def overlaps_any_word_relaxed(start, end, words, tol=0.05):\n",
    "    for _, w in words.iterrows():\n",
    "        if start < w[\"end\"] + tol and end > w[\"start\"] - tol:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "df_wav2vec_merged[\"overlaps_word\"] = df_wav2vec_merged.apply(\n",
    "    lambda r: overlaps_any_word_relaxed(\n",
    "        r[\"start\"], r[\"end\"], df_aligned_words\n",
    "    ),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "df_non_word = df_wav2vec_merged[~df_wav2vec_merged[\"overlaps_word\"]]\n",
    "df_non_word.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "d397d020",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# conservative mapping: only sounds we are confident about\n",
    "FILLER_MAP = {\n",
    "    \"A\": \"uh\",\n",
    "    \"E\": \"uh\",\n",
    "    \"U\": \"uh\",\n",
    "    \"M\": \"um\",\n",
    "    \"N\": \"um\",\n",
    "    \"MM\": \"um\",\n",
    "    \"NN\": \"um\",\n",
    "}\n",
    "\n",
    "\n",
    "def classify_non_word_event(row):\n",
    "    label = row[\"labels\"].upper()\n",
    "    duration = row[\"duration\"]\n",
    "\n",
    "    # Normalize repeated letters (e.g. MM → M)\n",
    "    norm = re.sub(r\"(.)\\1+\", r\"\\1\", label)\n",
    "\n",
    "    # Case 1: canonical filler sound\n",
    "    if norm in FILLER_MAP:\n",
    "        return {\n",
    "            \"type\": \"filler\",\n",
    "            \"raw_label\": label,\n",
    "            \"normalized\": norm,\n",
    "            \"text\": FILLER_MAP[norm],\n",
    "        }\n",
    "\n",
    "    # Case 2: looks like a real word fragment → stutter\n",
    "    if len(label) >= 2 and label.isalpha():\n",
    "        return {\n",
    "            \"type\": \"stutter\",\n",
    "            \"raw_label\": label,\n",
    "            \"normalized\": label.lower(),\n",
    "            \"text\": label.lower()\n",
    "        }\n",
    "\n",
    "    # Case 3: everything else → ignore\n",
    "    return None\n",
    "\n",
    "\n",
    "converted = []\n",
    "\n",
    "for _, row in df_non_word.iterrows():\n",
    "    result = classify_non_word_event(row)\n",
    "    if result:\n",
    "        converted.append({\n",
    "            \"type\": result[\"type\"],\n",
    "            \"text\": result[\"text\"],\n",
    "            \"raw_label\": result[\"raw_label\"],\n",
    "            \"start\": row[\"start\"],\n",
    "            \"end\": row[\"end\"],\n",
    "            \"duration\": row[\"duration\"]\n",
    "        })\n",
    "\n",
    "df_filler_events = pd.DataFrame(converted)\n",
    "df_filler_events.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "c64b9c25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>text</th>\n",
       "      <th>raw_text</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>duration</th>\n",
       "      <th>confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [type, text, raw_text, start, end, duration, confidence]\n",
       "Index: []"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filler_model = whisper.load_model(\"base\", device=\"cpu\")\n",
    "verbatim_result = filler_model.transcribe(\n",
    "    audio_file_path,\n",
    "    task=\"transcribe\",\n",
    "    temperature=0,\n",
    "    word_timestamps=True,\n",
    "    condition_on_previous_text=False,\n",
    "    initial_prompt=(\n",
    "        \"Transcribe verbatim. Include filler words like um, uh, er, \"\n",
    "        \"false starts, repetitions, and hesitations.\"\n",
    "    ),\n",
    "    fp16=False,\n",
    ")\n",
    "\n",
    "import re\n",
    "\n",
    "FILLER_PATTERN = re.compile(\n",
    "    r\"^(um+|uh+|erm+|er+|ah+|eh+)$\",\n",
    "    re.IGNORECASE\n",
    ")\n",
    "\n",
    "def normalize_whisper_token(token: str) -> str:\n",
    "    \"\"\"\n",
    "    Normalize Whisper word tokens like:\n",
    "    'um,' -> 'um'\n",
    "    'uh...' -> 'uh'\n",
    "    'erm-' -> 'erm'\n",
    "    \"\"\"\n",
    "    token = token.lower().strip()\n",
    "\n",
    "    # remove leading/trailing punctuation\n",
    "    token = re.sub(r\"^[^\\w]+|[^\\w]+$\", \"\", token)\n",
    "\n",
    "    return token\n",
    "\n",
    "\n",
    "whisper_fillers = []\n",
    "\n",
    "for seg in verbatim_result.get(\"segments\", []):\n",
    "    for w in seg.get(\"words\", []):\n",
    "        raw = w[\"word\"]\n",
    "        norm = normalize_whisper_token(raw)\n",
    "\n",
    "        if not norm:\n",
    "            continue\n",
    "\n",
    "        if FILLER_PATTERN.match(norm):\n",
    "            whisper_fillers.append({\n",
    "                \"type\": \"filler\",\n",
    "                \"text\": norm,                 # canonical filler\n",
    "                \"raw_text\": raw,              # keep original for debugging\n",
    "                \"start\": float(w[\"start\"]),\n",
    "                \"end\": float(w[\"end\"]),\n",
    "                \"duration\": float(w[\"end\"] - w[\"start\"]),\n",
    "                \"confidence\": float(w[\"probability\"]),\n",
    "            })\n",
    "if whisper_fillers:\n",
    "    df_whisper_fillers = pd.DataFrame(whisper_fillers)\n",
    "\n",
    "    # df_whisper_fillers = df_whisper_fillers[\n",
    "    #     (df_whisper_fillers[\"duration\"] >= 0.25) &\n",
    "    #     (df_whisper_fillers[\"confidence\"] >= 0.5)\n",
    "    # ].reset_index(drop=True)\n",
    "else:\n",
    "    df_whisper_fillers = pd.DataFrame(\n",
    "        columns=[\n",
    "            \"type\",\n",
    "            \"text\",\n",
    "            \"raw_text\",\n",
    "            \"start\",\n",
    "            \"end\",\n",
    "            \"duration\",\n",
    "            \"confidence\",\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "df_whisper_fillers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "4d05fae4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>style</th>\n",
       "      <th>type</th>\n",
       "      <th>text</th>\n",
       "      <th>raw_label</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [style, type, text, raw_label, start, end, duration]\n",
       "Index: []"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def overlaps_time(a_start, a_end, b_start, b_end, tol=0.08):\n",
    "    \"\"\"\n",
    "    Returns True if two time intervals overlap within tolerance.\n",
    "    \"\"\"\n",
    "    return (a_start < b_end + tol) and (a_end > b_start - tol)\n",
    "\n",
    "final_fillers = []\n",
    "\n",
    "FINAL_FILLER_COLUMNS = [\n",
    "    \"style\",\n",
    "    \"type\",\n",
    "    \"text\",\n",
    "    \"raw_label\",\n",
    "    \"start\",\n",
    "    \"end\",\n",
    "    \"duration\",\n",
    "]\n",
    "\n",
    "# 1️⃣ Add all wav2vec fillers first (ground truth)\n",
    "for _, row in df_filler_events.iterrows():\n",
    "    final_fillers.append({\n",
    "        \"style\": \"subtle\",\n",
    "        \"type\": row[\"type\"],\n",
    "        \"text\": row[\"text\"],\n",
    "        \"raw_label\": row.get(\"raw_label\", None),\n",
    "        \"start\": row[\"start\"],\n",
    "        \"end\": row[\"end\"],\n",
    "        \"duration\": row[\"duration\"],\n",
    "    })\n",
    "\n",
    "for _, wf in df_whisper_fillers.iterrows():\n",
    "    is_duplicate = False\n",
    "\n",
    "    for af in final_fillers:\n",
    "        if overlaps_time(\n",
    "            wf[\"start\"], wf[\"end\"],\n",
    "            af[\"start\"], af[\"end\"]\n",
    "        ):\n",
    "            is_duplicate = True\n",
    "            break\n",
    "\n",
    "    if not is_duplicate:\n",
    "        final_fillers.append({\n",
    "            \"style\": \"clear\",\n",
    "            \"type\": \"filler\",\n",
    "            \"text\": wf[\"text\"],\n",
    "            \"raw_label\": wf[\"raw_text\"],\n",
    "            \"start\": wf[\"start\"],\n",
    "            \"end\": wf[\"end\"],\n",
    "            \"duration\": wf[\"duration\"],\n",
    "        })\n",
    "\n",
    "df_final_fillers = pd.DataFrame(\n",
    "    final_fillers,\n",
    "    columns=FINAL_FILLER_COLUMNS\n",
    ")\n",
    "\n",
    "if not df_final_fillers.empty:\n",
    "    df_final_fillers = (\n",
    "        df_final_fillers\n",
    "        .sort_values(\"start\")\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "df_final_fillers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "50cce14e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'wpm': 159.30902111324374,\n",
       " 'fillers_per_min': 0.0,\n",
       " 'stutters_per_min': 0.0,\n",
       " 'long_pauses_per_min': 0.0,\n",
       " 'very_long_pauses_per_min': 0.0,\n",
       " 'pause_time_ratio': np.float64(0.09660908509277018),\n",
       " 'pause_variability': np.float64(0.1099210143115021),\n",
       " 'vocab_richness': 0.7349397590361446,\n",
       " 'repetition_ratio': np.float64(0.12048192771084337)}"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %%\n",
    "# ---------- ENHANCED NORMALIZATION ----------\n",
    "\n",
    "duration_min = max(total_duration / 60.0, 0.5)\n",
    "\n",
    "# Fillers & stutters\n",
    "filler_events = df_final_fillers[df_final_fillers[\"type\"] == \"filler\"]\n",
    "stutter_events = df_final_fillers[df_final_fillers[\"type\"] == \"stutter\"]\n",
    "\n",
    "fillers_per_min = len(filler_events) / duration_min\n",
    "stutters_per_min = len(stutter_events) / duration_min\n",
    "\n",
    "# Pauses\n",
    "pauses = df_words[\"start\"].iloc[1:].values - df_words[\"end\"].iloc[:-1].values\n",
    "long_pauses = pauses[pauses > 1.0]\n",
    "very_long_pauses = pauses[pauses > 2.0]\n",
    "\n",
    "long_pauses_per_min = len(long_pauses) / duration_min\n",
    "very_long_pauses_per_min = len(very_long_pauses) / duration_min\n",
    "pause_time_ratio = pauses[pauses > 0].sum() / total_duration\n",
    "\n",
    "# Lexical\n",
    "words_clean = df_words[\"word\"].str.lower()\n",
    "vocab_richness = words_clean.nunique() / len(words_clean)\n",
    "repetition_ratio = words_clean.value_counts().iloc[0] / len(words_clean)\n",
    "\n",
    "# Temporal fluency instability (variance of gaps)\n",
    "pause_variability = pauses.std() if len(pauses) > 5 else 0.0\n",
    "\n",
    "normalized_metrics = {\n",
    "    \"wpm\": words_per_minute,\n",
    "    \"fillers_per_min\": fillers_per_min,\n",
    "    \"stutters_per_min\": stutters_per_min,\n",
    "    \"long_pauses_per_min\": long_pauses_per_min,\n",
    "    \"very_long_pauses_per_min\": very_long_pauses_per_min,\n",
    "    \"pause_time_ratio\": pause_time_ratio,\n",
    "    \"pause_variability\": pause_variability,\n",
    "    \"vocab_richness\": vocab_richness,\n",
    "    \"repetition_ratio\": repetition_ratio,\n",
    "}\n",
    "\n",
    "normalized_metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "d58fbffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONTEXT_CONFIG = {\n",
    "    \"conversational\": {\n",
    "        \"pause_tolerance\": 1.0,\n",
    "        \"pause_variability_tolerance\": 1.0,\n",
    "    },\n",
    "    \"narrative\": {\n",
    "        \"pause_tolerance\": 1.4,          # allow more long pauses\n",
    "        \"pause_variability_tolerance\": 1.3,\n",
    "    },\n",
    "    \"presentation\": {\n",
    "        \"pause_tolerance\": 1.2,\n",
    "        \"pause_variability_tolerance\": 1.1,\n",
    "    },\n",
    "    \"interview\": {\n",
    "        \"pause_tolerance\": 0.9,          # stricter\n",
    "        \"pause_variability_tolerance\": 0.9,\n",
    "    },\n",
    "}\n",
    "\n",
    "context = CONTEXT_CONFIG.get(speech_context, CONTEXT_CONFIG[\"conversational\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "60d6a570",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %%\n",
    "# ---------- CONSISTENT FLUENCY SCORING ----------\n",
    "\n",
    "import math\n",
    "\n",
    "def clamp01(x):\n",
    "    return max(0.0, min(1.0, x))\n",
    "\n",
    "\n",
    "# ---- Subscores (0–1, higher = better) ----\n",
    "\n",
    "# Speech rate (ASYMMETRIC)\n",
    "wpm = normalized_metrics[\"wpm\"]\n",
    "\n",
    "if wpm < 110:  # too slow hurts fluency hard\n",
    "    speech_rate_score = clamp01((wpm - 70) / 40)\n",
    "elif wpm <= 170:  # optimal band\n",
    "    speech_rate_score = 1.0\n",
    "else:  # too fast hurts gently\n",
    "    speech_rate_score = clamp01(1 - (wpm - 170) / 120)\n",
    "\n",
    "\n",
    "# Pauses (structural)\n",
    "pause_score = clamp01(\n",
    "    1 - (\n",
    "        normalized_metrics[\"long_pauses_per_min\"]\n",
    "        / (4.0 * context[\"pause_tolerance\"])\n",
    "    )\n",
    ")\n",
    "\n",
    "# Fillers (structural)\n",
    "filler_score = clamp01(\n",
    "    1 - (normalized_metrics[\"fillers_per_min\"] / 6.0)\n",
    ")\n",
    "\n",
    "# Stability (structural)\n",
    "stability_score = clamp01(\n",
    "    1 - (\n",
    "        normalized_metrics[\"pause_variability\"]\n",
    "        / (0.7 * context[\"pause_variability_tolerance\"])\n",
    "    )\n",
    ")\n",
    "\n",
    "# Lexical quality (STYLE)\n",
    "lexical_score = clamp01(\n",
    "    0.65 * normalized_metrics[\"vocab_richness\"]\n",
    "    + 0.35 * (1 - normalized_metrics[\"repetition_ratio\"])\n",
    ")\n",
    "\n",
    "\n",
    "# ---- Weighted aggregation ----\n",
    "# Structural dimensions dominate readiness\n",
    "raw_score = (\n",
    "    0.30 * pause_score +\n",
    "    0.25 * filler_score +\n",
    "    0.20 * stability_score +\n",
    "    0.15 * speech_rate_score +\n",
    "    0.10 * lexical_score\n",
    ")\n",
    "\n",
    "fluency_score = int(round(100 * clamp01(raw_score)))\n",
    "fluency_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "eeee627c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %%\n",
    "# ---------- ISSUE DETECTION ----------\n",
    "\n",
    "issues = []\n",
    "\n",
    "def issue(severity, issue_id, root_cause, score_impact):\n",
    "    return {\n",
    "        \"issue\": issue_id,\n",
    "        \"severity\": severity,\n",
    "        \"root_cause\": root_cause,\n",
    "        \"score_impact\": score_impact\n",
    "    }\n",
    "\n",
    "\n",
    "# Structural blockers\n",
    "if pause_score < 0.6:\n",
    "    issues.append(issue(\n",
    "        \"high\",\n",
    "        \"hesitation_structure\",\n",
    "        \"Pauses frequently interrupt sentence flow.\",\n",
    "        int((1 - pause_score) * 30)\n",
    "    ))\n",
    "\n",
    "if filler_score < 0.6:\n",
    "    issues.append(issue(\n",
    "        \"high\",\n",
    "        \"filler_dependency\",\n",
    "        \"Fillers replace silent planning pauses.\",\n",
    "        int((1 - filler_score) * 25)\n",
    "    ))\n",
    "\n",
    "if stability_score < 0.6:\n",
    "    issues.append(issue(\n",
    "        \"medium\",\n",
    "        \"delivery_instability\",\n",
    "        \"Speech rhythm varies unpredictably.\",\n",
    "        int((1 - stability_score) * 20)\n",
    "    ))\n",
    "\n",
    "# Style issues (never blockers alone)\n",
    "if speech_rate_score < 0.7:\n",
    "    issues.append(issue(\n",
    "        \"medium\",\n",
    "        \"delivery_pacing\",\n",
    "        \"Speech rate is faster than optimal for clarity.\",\n",
    "        int((1 - speech_rate_score) * 15)\n",
    "    ))\n",
    "\n",
    "if lexical_score < 0.5:\n",
    "    issues.append(issue(\n",
    "        \"low\",\n",
    "        \"lexical_simplicity\",\n",
    "        \"Frequent reuse of common vocabulary.\",\n",
    "        int((1 - lexical_score) * 10)\n",
    "    ))\n",
    "\n",
    "\n",
    "issues = sorted(issues, key=lambda x: x[\"score_impact\"], reverse=True)\n",
    "issues\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "f0b1848b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ready'"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %%\n",
    "# ---------- READINESS JUDGMENT ----------\n",
    "\n",
    "high_issues = [i for i in issues if i[\"severity\"] == \"high\"]\n",
    "medium_issues = [i for i in issues if i[\"severity\"] == \"medium\"]\n",
    "\n",
    "if len(high_issues) >= 2:\n",
    "    readiness = \"not_ready\"\n",
    "elif len(high_issues) == 1:\n",
    "    readiness = \"borderline\"\n",
    "elif len(medium_issues) >= 2:\n",
    "    readiness = \"borderline\"\n",
    "elif fluency_score >= 80:\n",
    "    readiness = \"ready\"\n",
    "else:\n",
    "    readiness = \"borderline\"\n",
    "\n",
    "readiness\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "bc527a35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'percentile': 80,\n",
       " 'target_score': 80,\n",
       " 'score_gap': 0,\n",
       " 'estimated_guided_practice_hours': 0.0}"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %%\n",
    "# ---------- BENCHMARKING ----------\n",
    "\n",
    "# v1 calibrated bands (replace with data later)\n",
    "if fluency_score >= 85:\n",
    "    percentile = 80\n",
    "elif fluency_score >= 75:\n",
    "    percentile = 65\n",
    "elif fluency_score >= 65:\n",
    "    percentile = 50\n",
    "else:\n",
    "    percentile = 30\n",
    "\n",
    "score_gap = (\n",
    "    max(0, 80 - fluency_score)\n",
    "    if readiness != \"ready\"\n",
    "    else 0\n",
    ")\n",
    "\n",
    "benchmarking = {\n",
    "    \"percentile\": percentile,\n",
    "    \"target_score\": 80,\n",
    "    \"score_gap\": score_gap,\n",
    "    \"estimated_guided_practice_hours\": score_gap * 0.6,\n",
    "}\n",
    "\n",
    "\n",
    "benchmarking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "ae7d1e1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'primary_issues': [], 'action_plan': []}"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %%\n",
    "# ---------- OPINIONS ----------\n",
    "\n",
    "action_plan = []\n",
    "\n",
    "for idx, issue in enumerate(issues[:3]):\n",
    "    action_plan.append({\n",
    "        \"priority\": idx + 1,\n",
    "        \"focus\": issue[\"issue\"],\n",
    "        \"instruction\": {\n",
    "            \"hesitation_structure\": \"Pause only after completing full clauses.\",\n",
    "            \"filler_dependency\": \"Replace fillers with silent pauses under 300ms.\",\n",
    "            \"delivery_instability\": \"Practice steady pacing with metronome drills.\",\n",
    "            \"delivery_pacing\": \"Reduce speed slightly while maintaining energy.\",\n",
    "            \"lexical_simplicity\": \"Actively substitute repeated words during rehearsal.\"\n",
    "        }[issue[\"issue\"]],\n",
    "        \"expected_score_gain\": issue[\"score_impact\"]\n",
    "    })\n",
    "\n",
    "opinions = {\n",
    "    \"primary_issues\": issues,\n",
    "    \"action_plan\": action_plan\n",
    "}\n",
    "\n",
    "opinions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "f76f4893",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'verdict': {'fluency_score': 95, 'readiness': 'ready', 'confidence': 0.92},\n",
       " 'benchmarking': {'percentile': 80,\n",
       "  'target_score': 80,\n",
       "  'score_gap': 0,\n",
       "  'estimated_guided_practice_hours': 0.0},\n",
       " 'normalized_metrics': {'wpm': 159.30902111324374,\n",
       "  'fillers_per_min': 0.0,\n",
       "  'stutters_per_min': 0.0,\n",
       "  'long_pauses_per_min': 0.0,\n",
       "  'very_long_pauses_per_min': 0.0,\n",
       "  'pause_time_ratio': np.float64(0.09660908509277018),\n",
       "  'pause_variability': np.float64(0.1099210143115021),\n",
       "  'vocab_richness': 0.7349397590361446,\n",
       "  'repetition_ratio': np.float64(0.12048192771084337)},\n",
       " 'opinions': {'primary_issues': [], 'action_plan': []},\n",
       " 'word_timestamps': [{'word': 'She',\n",
       "   'start': 0.0,\n",
       "   'end': 0.94,\n",
       "   'duration': 0.94,\n",
       "   'confidence': 0.7459069490432739},\n",
       "  {'word': 'poured',\n",
       "   'start': 0.94,\n",
       "   'end': 1.2,\n",
       "   'duration': 0.26,\n",
       "   'confidence': 0.9895564913749695},\n",
       "  {'word': 'concrete',\n",
       "   'start': 1.2,\n",
       "   'end': 1.84,\n",
       "   'duration': 0.6400000000000001,\n",
       "   'confidence': 0.9994962215423584},\n",
       "  {'word': 'straight',\n",
       "   'start': 1.84,\n",
       "   'end': 2.32,\n",
       "   'duration': 0.47999999999999976,\n",
       "   'confidence': 0.9742660522460938},\n",
       "  {'word': 'into',\n",
       "   'start': 2.32,\n",
       "   'end': 2.74,\n",
       "   'duration': 0.4200000000000004,\n",
       "   'confidence': 0.9688946008682251},\n",
       "  {'word': 'the',\n",
       "   'start': 2.74,\n",
       "   'end': 3.0,\n",
       "   'duration': 0.2599999999999998,\n",
       "   'confidence': 0.9975787997245789},\n",
       "  {'word': 'storm',\n",
       "   'start': 3.0,\n",
       "   'end': 3.34,\n",
       "   'duration': 0.33999999999999986,\n",
       "   'confidence': 0.9846946597099304},\n",
       "  {'word': 'pipe',\n",
       "   'start': 3.34,\n",
       "   'end': 3.6,\n",
       "   'duration': 0.26000000000000023,\n",
       "   'confidence': 0.9190976619720459},\n",
       "  {'word': 'at',\n",
       "   'start': 3.6,\n",
       "   'end': 3.96,\n",
       "   'duration': 0.3599999999999999,\n",
       "   'confidence': 0.9885851740837097},\n",
       "  {'word': 'the',\n",
       "   'start': 3.96,\n",
       "   'end': 4.1,\n",
       "   'duration': 0.13999999999999968,\n",
       "   'confidence': 0.9987055063247681},\n",
       "  {'word': 'edge',\n",
       "   'start': 4.1,\n",
       "   'end': 4.36,\n",
       "   'duration': 0.2600000000000007,\n",
       "   'confidence': 0.9959456324577332},\n",
       "  {'word': 'of',\n",
       "   'start': 4.36,\n",
       "   'end': 4.54,\n",
       "   'duration': 0.17999999999999972,\n",
       "   'confidence': 0.9977784752845764},\n",
       "  {'word': 'her',\n",
       "   'start': 4.54,\n",
       "   'end': 4.68,\n",
       "   'duration': 0.13999999999999968,\n",
       "   'confidence': 0.9985252022743225},\n",
       "  {'word': 'yard,',\n",
       "   'start': 4.68,\n",
       "   'end': 5.12,\n",
       "   'duration': 0.4400000000000004,\n",
       "   'confidence': 0.9966716766357422},\n",
       "  {'word': 'and',\n",
       "   'start': 5.4,\n",
       "   'end': 5.48,\n",
       "   'duration': 0.08000000000000007,\n",
       "   'confidence': 0.9935482144355774},\n",
       "  {'word': 'the',\n",
       "   'start': 5.48,\n",
       "   'end': 5.6,\n",
       "   'duration': 0.11999999999999922,\n",
       "   'confidence': 0.998102605342865},\n",
       "  {'word': 'wet',\n",
       "   'start': 5.6,\n",
       "   'end': 5.8,\n",
       "   'duration': 0.20000000000000018,\n",
       "   'confidence': 0.646396279335022},\n",
       "  {'word': 'cement',\n",
       "   'start': 5.8,\n",
       "   'end': 6.16,\n",
       "   'duration': 0.3600000000000003,\n",
       "   'confidence': 0.9880685210227966},\n",
       "  {'word': 'hardened',\n",
       "   'start': 6.16,\n",
       "   'end': 6.76,\n",
       "   'duration': 0.5999999999999996,\n",
       "   'confidence': 0.9038064479827881},\n",
       "  {'word': 'inside,',\n",
       "   'start': 6.76,\n",
       "   'end': 7.46,\n",
       "   'duration': 0.7000000000000002,\n",
       "   'confidence': 0.9975353479385376},\n",
       "  {'word': 'sealing',\n",
       "   'start': 8.02,\n",
       "   'end': 8.22,\n",
       "   'duration': 0.20000000000000107,\n",
       "   'confidence': 0.9515588879585266},\n",
       "  {'word': 'the',\n",
       "   'start': 8.22,\n",
       "   'end': 8.42,\n",
       "   'duration': 0.1999999999999993,\n",
       "   'confidence': 0.9991262555122375},\n",
       "  {'word': 'pipe',\n",
       "   'start': 8.42,\n",
       "   'end': 8.8,\n",
       "   'duration': 0.3800000000000008,\n",
       "   'confidence': 0.9885243773460388},\n",
       "  {'word': 'so',\n",
       "   'start': 8.8,\n",
       "   'end': 9.12,\n",
       "   'duration': 0.3199999999999985,\n",
       "   'confidence': 0.9421839714050293},\n",
       "  {'word': 'water',\n",
       "   'start': 9.12,\n",
       "   'end': 9.58,\n",
       "   'duration': 0.46000000000000085,\n",
       "   'confidence': 0.9616215825080872},\n",
       "  {'word': \"couldn't\",\n",
       "   'start': 9.58,\n",
       "   'end': 10.16,\n",
       "   'duration': 0.5800000000000001,\n",
       "   'confidence': 0.990556925535202},\n",
       "  {'word': 'flow',\n",
       "   'start': 10.16,\n",
       "   'end': 10.38,\n",
       "   'duration': 0.22000000000000064,\n",
       "   'confidence': 0.9856776595115662},\n",
       "  {'word': 'through.',\n",
       "   'start': 10.38,\n",
       "   'end': 10.76,\n",
       "   'duration': 0.379999999999999,\n",
       "   'confidence': 0.9951216578483582},\n",
       "  {'word': 'You',\n",
       "   'start': 11.12,\n",
       "   'end': 11.22,\n",
       "   'duration': 0.10000000000000142,\n",
       "   'confidence': 0.9618932008743286},\n",
       "  {'word': 'see,',\n",
       "   'start': 11.22,\n",
       "   'end': 11.36,\n",
       "   'duration': 0.1399999999999988,\n",
       "   'confidence': 0.9965026378631592},\n",
       "  {'word': 'that',\n",
       "   'start': 11.6,\n",
       "   'end': 11.76,\n",
       "   'duration': 0.16000000000000014,\n",
       "   'confidence': 0.996667206287384},\n",
       "  {'word': 'pipe',\n",
       "   'start': 11.76,\n",
       "   'end': 12.18,\n",
       "   'duration': 0.41999999999999993,\n",
       "   'confidence': 0.9993589520454407},\n",
       "  {'word': 'was',\n",
       "   'start': 12.18,\n",
       "   'end': 12.52,\n",
       "   'duration': 0.33999999999999986,\n",
       "   'confidence': 0.9979150891304016},\n",
       "  {'word': 'part',\n",
       "   'start': 12.52,\n",
       "   'end': 12.84,\n",
       "   'duration': 0.3200000000000003,\n",
       "   'confidence': 0.9938161373138428},\n",
       "  {'word': 'of',\n",
       "   'start': 12.84,\n",
       "   'end': 13.24,\n",
       "   'duration': 0.40000000000000036,\n",
       "   'confidence': 0.9982187151908875},\n",
       "  {'word': 'the',\n",
       "   'start': 13.24,\n",
       "   'end': 13.34,\n",
       "   'duration': 0.09999999999999964,\n",
       "   'confidence': 0.9948659539222717},\n",
       "  {'word': \"neighborhood's\",\n",
       "   'start': 13.34,\n",
       "   'end': 14.14,\n",
       "   'duration': 0.8000000000000007,\n",
       "   'confidence': 0.9599164426326752},\n",
       "  {'word': 'draining',\n",
       "   'start': 14.14,\n",
       "   'end': 14.42,\n",
       "   'duration': 0.27999999999999936,\n",
       "   'confidence': 0.9670461416244507},\n",
       "  {'word': 'system,',\n",
       "   'start': 14.42,\n",
       "   'end': 15.02,\n",
       "   'duration': 0.5999999999999996,\n",
       "   'confidence': 0.9989050626754761},\n",
       "  {'word': 'carrying',\n",
       "   'start': 15.28,\n",
       "   'end': 15.56,\n",
       "   'duration': 0.28000000000000114,\n",
       "   'confidence': 0.9948139190673828},\n",
       "  {'word': 'rainwater',\n",
       "   'start': 15.56,\n",
       "   'end': 16.32,\n",
       "   'duration': 0.7599999999999998,\n",
       "   'confidence': 0.837280809879303},\n",
       "  {'word': 'underground',\n",
       "   'start': 16.32,\n",
       "   'end': 17.04,\n",
       "   'duration': 0.7199999999999989,\n",
       "   'confidence': 0.9937388896942139},\n",
       "  {'word': 'to',\n",
       "   'start': 17.04,\n",
       "   'end': 17.48,\n",
       "   'duration': 0.4400000000000013,\n",
       "   'confidence': 0.9804674386978149},\n",
       "  {'word': 'a',\n",
       "   'start': 17.48,\n",
       "   'end': 17.58,\n",
       "   'duration': 0.09999999999999787,\n",
       "   'confidence': 0.997239351272583},\n",
       "  {'word': 'nearby',\n",
       "   'start': 17.58,\n",
       "   'end': 17.84,\n",
       "   'duration': 0.26000000000000156,\n",
       "   'confidence': 0.9997708201408386},\n",
       "  {'word': 'pond',\n",
       "   'start': 17.84,\n",
       "   'end': 18.54,\n",
       "   'duration': 0.6999999999999993,\n",
       "   'confidence': 0.9896911978721619},\n",
       "  {'word': 'where',\n",
       "   'start': 18.54,\n",
       "   'end': 18.88,\n",
       "   'duration': 0.33999999999999986,\n",
       "   'confidence': 0.9654194712638855},\n",
       "  {'word': 'it',\n",
       "   'start': 18.88,\n",
       "   'end': 19.08,\n",
       "   'duration': 0.1999999999999993,\n",
       "   'confidence': 0.9980059266090393},\n",
       "  {'word': 'could',\n",
       "   'start': 19.08,\n",
       "   'end': 19.22,\n",
       "   'duration': 0.14000000000000057,\n",
       "   'confidence': 0.9961667656898499},\n",
       "  {'word': 'collect.',\n",
       "   'start': 19.22,\n",
       "   'end': 19.64,\n",
       "   'duration': 0.4200000000000017,\n",
       "   'confidence': 0.9991167187690735},\n",
       "  {'word': 'But',\n",
       "   'start': 20.08,\n",
       "   'end': 20.2,\n",
       "   'duration': 0.120000000000001,\n",
       "   'confidence': 0.9903085827827454},\n",
       "  {'word': 'the',\n",
       "   'start': 20.2,\n",
       "   'end': 20.32,\n",
       "   'duration': 0.120000000000001,\n",
       "   'confidence': 0.9870166182518005},\n",
       "  {'word': 'woman',\n",
       "   'start': 20.32,\n",
       "   'end': 20.54,\n",
       "   'duration': 0.21999999999999886,\n",
       "   'confidence': 0.9722294807434082},\n",
       "  {'word': 'claimed',\n",
       "   'start': 20.54,\n",
       "   'end': 21.14,\n",
       "   'duration': 0.6000000000000014,\n",
       "   'confidence': 0.997725784778595},\n",
       "  {'word': 'that',\n",
       "   'start': 21.14,\n",
       "   'end': 21.34,\n",
       "   'duration': 0.1999999999999993,\n",
       "   'confidence': 0.9822148680686951},\n",
       "  {'word': 'the',\n",
       "   'start': 21.34,\n",
       "   'end': 21.48,\n",
       "   'duration': 0.14000000000000057,\n",
       "   'confidence': 0.9981556534767151},\n",
       "  {'word': 'drain',\n",
       "   'start': 21.48,\n",
       "   'end': 21.8,\n",
       "   'duration': 0.3200000000000003,\n",
       "   'confidence': 0.9853900671005249},\n",
       "  {'word': 'was',\n",
       "   'start': 21.8,\n",
       "   'end': 22.08,\n",
       "   'duration': 0.2799999999999976,\n",
       "   'confidence': 0.9991877675056458},\n",
       "  {'word': 'eating',\n",
       "   'start': 22.08,\n",
       "   'end': 22.38,\n",
       "   'duration': 0.3000000000000007,\n",
       "   'confidence': 0.9778344631195068},\n",
       "  {'word': 'away',\n",
       "   'start': 22.38,\n",
       "   'end': 22.68,\n",
       "   'duration': 0.3000000000000007,\n",
       "   'confidence': 0.9482600688934326},\n",
       "  {'word': 'at',\n",
       "   'start': 22.68,\n",
       "   'end': 23.0,\n",
       "   'duration': 0.3200000000000003,\n",
       "   'confidence': 0.9928292632102966},\n",
       "  {'word': 'her',\n",
       "   'start': 23.0,\n",
       "   'end': 23.28,\n",
       "   'duration': 0.28000000000000114,\n",
       "   'confidence': 0.9850100874900818},\n",
       "  {'word': 'yard',\n",
       "   'start': 23.28,\n",
       "   'end': 23.8,\n",
       "   'duration': 0.5199999999999996,\n",
       "   'confidence': 0.995947539806366},\n",
       "  {'word': 'and',\n",
       "   'start': 23.8,\n",
       "   'end': 24.14,\n",
       "   'duration': 0.33999999999999986,\n",
       "   'confidence': 0.9106078743934631},\n",
       "  {'word': 'causing',\n",
       "   'start': 24.14,\n",
       "   'end': 24.58,\n",
       "   'duration': 0.4399999999999977,\n",
       "   'confidence': 0.9962236881256104},\n",
       "  {'word': 'sinkholes.',\n",
       "   'start': 24.58,\n",
       "   'end': 25.32,\n",
       "   'duration': 0.740000000000002,\n",
       "   'confidence': 0.9227627515792847},\n",
       "  {'word': 'Once',\n",
       "   'start': 25.32,\n",
       "   'end': 25.88,\n",
       "   'duration': 0.5599999999999987,\n",
       "   'confidence': 0.9407613277435303},\n",
       "  {'word': 'the',\n",
       "   'start': 25.88,\n",
       "   'end': 26.1,\n",
       "   'duration': 0.22000000000000242,\n",
       "   'confidence': 0.9978823065757751},\n",
       "  {'word': 'pipe',\n",
       "   'start': 26.1,\n",
       "   'end': 26.32,\n",
       "   'duration': 0.21999999999999886,\n",
       "   'confidence': 0.960493266582489},\n",
       "  {'word': 'was',\n",
       "   'start': 26.32,\n",
       "   'end': 26.48,\n",
       "   'duration': 0.16000000000000014,\n",
       "   'confidence': 0.9958463311195374},\n",
       "  {'word': 'sealed,',\n",
       "   'start': 26.48,\n",
       "   'end': 26.92,\n",
       "   'duration': 0.4400000000000013,\n",
       "   'confidence': 0.9975128173828125},\n",
       "  {'word': 'the',\n",
       "   'start': 27.18,\n",
       "   'end': 27.22,\n",
       "   'duration': 0.03999999999999915,\n",
       "   'confidence': 0.9958261847496033},\n",
       "  {'word': 'water',\n",
       "   'start': 27.22,\n",
       "   'end': 27.54,\n",
       "   'duration': 0.3200000000000003,\n",
       "   'confidence': 0.9994651675224304},\n",
       "  {'word': 'had',\n",
       "   'start': 27.54,\n",
       "   'end': 27.82,\n",
       "   'duration': 0.28000000000000114,\n",
       "   'confidence': 0.9963860511779785},\n",
       "  {'word': 'nowhere',\n",
       "   'start': 27.82,\n",
       "   'end': 28.14,\n",
       "   'duration': 0.3200000000000003,\n",
       "   'confidence': 0.9454728960990906},\n",
       "  {'word': 'to',\n",
       "   'start': 28.14,\n",
       "   'end': 28.58,\n",
       "   'duration': 0.4399999999999977,\n",
       "   'confidence': 0.9993008375167847},\n",
       "  {'word': 'go.',\n",
       "   'start': 28.58,\n",
       "   'end': 28.92,\n",
       "   'duration': 0.3400000000000034,\n",
       "   'confidence': 0.9992488026618958},\n",
       "  {'word': 'Eventually,',\n",
       "   'start': 29.26,\n",
       "   'end': 29.7,\n",
       "   'duration': 0.4399999999999977,\n",
       "   'confidence': 0.9971805810928345},\n",
       "  {'word': 'it',\n",
       "   'start': 29.98,\n",
       "   'end': 30.06,\n",
       "   'duration': 0.0799999999999983,\n",
       "   'confidence': 0.998432457447052},\n",
       "  {'word': 'pooled',\n",
       "   'start': 30.06,\n",
       "   'end': 30.68,\n",
       "   'duration': 0.620000000000001,\n",
       "   'confidence': 0.8507256805896759},\n",
       "  {'word': 'on',\n",
       "   'start': 30.68,\n",
       "   'end': 30.76,\n",
       "   'duration': 0.08000000000000185,\n",
       "   'confidence': 0.9946261048316956},\n",
       "  {'word': 'the',\n",
       "   'start': 30.76,\n",
       "   'end': 30.9,\n",
       "   'duration': 0.13999999999999702,\n",
       "   'confidence': 0.998867392539978},\n",
       "  {'word': 'street.',\n",
       "   'start': 30.9,\n",
       "   'end': 31.26,\n",
       "   'duration': 0.360000000000003,\n",
       "   'confidence': 0.9855177402496338}],\n",
       " 'segment_timestamps': [{'text': 'She poured concrete straight into the storm pipe at the edge of her yard, and the wet cement',\n",
       "   'start': 0.0,\n",
       "   'end': 6.16,\n",
       "   'duration': 6.16,\n",
       "   'avg_word_confidence': 0.9545454846488105},\n",
       "  {'text': \"hardened inside, sealing the pipe so water couldn't flow through.\",\n",
       "   'start': 6.16,\n",
       "   'end': 10.76,\n",
       "   'duration': 4.6,\n",
       "   'avg_word_confidence': 0.9715713113546371},\n",
       "  {'text': \"You see, that pipe was part of the neighborhood's draining system, carrying rainwater underground\",\n",
       "   'start': 11.12,\n",
       "   'end': 17.04,\n",
       "   'duration': 5.92,\n",
       "   'avg_word_confidence': 0.9779242255858013},\n",
       "  {'text': 'to a nearby pond where it could collect.',\n",
       "   'start': 17.04,\n",
       "   'end': 19.64,\n",
       "   'duration': 2.6000000000000014,\n",
       "   'avg_word_confidence': 0.9907347112894058},\n",
       "  {'text': 'But the woman claimed that the drain was eating away at her yard and causing sinkholes.',\n",
       "   'start': 20.08,\n",
       "   'end': 25.32,\n",
       "   'duration': 5.240000000000002,\n",
       "   'avg_word_confidence': 0.9776065349578857},\n",
       "  {'text': 'Once the pipe was sealed, the water had nowhere to go.',\n",
       "   'start': 25.32,\n",
       "   'end': 28.92,\n",
       "   'duration': 3.6000000000000014,\n",
       "   'avg_word_confidence': 0.984381453557448},\n",
       "  {'text': 'Eventually, it pooled on the street.',\n",
       "   'start': 29.26,\n",
       "   'end': 31.26,\n",
       "   'duration': 2.0,\n",
       "   'avg_word_confidence': 0.9708916594584783}],\n",
       " 'filler_events': [],\n",
       " 'aligned_words': [{'word': 'she', 'start': 0.0, 'end': 0.966},\n",
       "  {'word': 'poured', 'start': 1.047, 'end': 1.308},\n",
       "  {'word': 'concrete', 'start': 1.409, 'end': 2.013},\n",
       "  {'word': 'straight', 'start': 2.174, 'end': 2.496},\n",
       "  {'word': 'into', 'start': 2.637, 'end': 2.919},\n",
       "  {'word': 'the', 'start': 2.939, 'end': 3.04},\n",
       "  {'word': 'storm', 'start': 3.1, 'end': 3.402},\n",
       "  {'word': 'pipe', 'start': 3.483, 'end': 3.764},\n",
       "  {'word': 'at', 'start': 3.966, 'end': 4.026},\n",
       "  {'word': 'the', 'start': 4.046, 'end': 4.167},\n",
       "  {'word': 'edge', 'start': 4.308, 'end': 4.449},\n",
       "  {'word': 'of', 'start': 4.489, 'end': 4.529},\n",
       "  {'word': 'her', 'start': 4.57, 'end': 4.731},\n",
       "  {'word': 'yard,', 'start': 4.771, 'end': 5.234},\n",
       "  {'word': 'and', 'start': 5.476, 'end': 5.556},\n",
       "  {'word': 'the', 'start': 5.596, 'end': 5.657},\n",
       "  {'word': 'wet', 'start': 5.717, 'end': 5.959},\n",
       "  {'word': 'cement', 'start': 5.979, 'end': 6.18},\n",
       "  {'word': 'hardened', 'start': 6.16, 'end': 6.927},\n",
       "  {'word': 'inside,', 'start': 6.967, 'end': 7.734},\n",
       "  {'word': 'sealing', 'start': 7.774, 'end': 8.359},\n",
       "  {'word': 'the', 'start': 8.399, 'end': 8.48},\n",
       "  {'word': 'pipe', 'start': 8.541, 'end': 8.884},\n",
       "  {'word': 'so', 'start': 9.146, 'end': 9.227},\n",
       "  {'word': 'water', 'start': 9.368, 'end': 9.731},\n",
       "  {'word': \"couldn't\", 'start': 9.852, 'end': 10.155},\n",
       "  {'word': 'flow', 'start': 10.316, 'end': 10.538},\n",
       "  {'word': 'through.', 'start': 10.578, 'end': 10.78},\n",
       "  {'word': 'you', 'start': 11.12, 'end': 11.241},\n",
       "  {'word': 'see,', 'start': 11.281, 'end': 11.462},\n",
       "  {'word': 'that', 'start': 11.603, 'end': 11.805},\n",
       "  {'word': 'pipe', 'start': 11.946, 'end': 12.268},\n",
       "  {'word': 'was', 'start': 12.409, 'end': 12.55},\n",
       "  {'word': 'part', 'start': 12.65, 'end': 12.993},\n",
       "  {'word': 'of', 'start': 13.194, 'end': 13.234},\n",
       "  {'word': 'the', 'start': 13.295, 'end': 13.395},\n",
       "  {'word': \"neighborhood's\", 'start': 13.436, 'end': 14.06},\n",
       "  {'word': 'draining', 'start': 14.181, 'end': 14.624},\n",
       "  {'word': 'system,', 'start': 14.704, 'end': 15.107},\n",
       "  {'word': 'carrying', 'start': 15.308, 'end': 15.711},\n",
       "  {'word': 'rainwater', 'start': 15.751, 'end': 16.456},\n",
       "  {'word': 'underground', 'start': 16.617, 'end': 17.06},\n",
       "  {'word': 'to', 'start': 17.04, 'end': 17.263},\n",
       "  {'word': 'a', 'start': 17.284, 'end': 17.304},\n",
       "  {'word': 'nearby', 'start': 17.67, 'end': 18.056},\n",
       "  {'word': 'pond', 'start': 18.157, 'end': 18.624},\n",
       "  {'word': 'where', 'start': 18.665, 'end': 19.01},\n",
       "  {'word': 'it', 'start': 19.051, 'end': 19.092},\n",
       "  {'word': 'could', 'start': 19.152, 'end': 19.295},\n",
       "  {'word': 'collect.', 'start': 19.396, 'end': 19.66},\n",
       "  {'word': 'but', 'start': 20.08, 'end': 20.241},\n",
       "  {'word': 'the', 'start': 20.261, 'end': 20.362},\n",
       "  {'word': 'woman', 'start': 20.423, 'end': 20.664},\n",
       "  {'word': 'claimed', 'start': 20.765, 'end': 21.188},\n",
       "  {'word': 'that', 'start': 21.209, 'end': 21.41},\n",
       "  {'word': 'the', 'start': 21.43, 'end': 21.511},\n",
       "  {'word': 'drain', 'start': 21.571, 'end': 21.954},\n",
       "  {'word': 'was', 'start': 22.035, 'end': 22.136},\n",
       "  {'word': 'eating', 'start': 22.297, 'end': 22.498},\n",
       "  {'word': 'away', 'start': 22.559, 'end': 22.801},\n",
       "  {'word': 'at', 'start': 22.942, 'end': 23.022},\n",
       "  {'word': 'her', 'start': 23.043, 'end': 23.466},\n",
       "  {'word': 'yard', 'start': 23.567, 'end': 23.95},\n",
       "  {'word': 'and', 'start': 24.131, 'end': 24.212},\n",
       "  {'word': 'causing', 'start': 24.312, 'end': 24.675},\n",
       "  {'word': 'sinkholes.', 'start': 24.796, 'end': 25.34},\n",
       "  {'word': 'once', 'start': 25.32, 'end': 25.967},\n",
       "  {'word': 'the', 'start': 26.048, 'end': 26.129},\n",
       "  {'word': 'pipe', 'start': 26.169, 'end': 26.372},\n",
       "  {'word': 'was', 'start': 26.412, 'end': 26.533},\n",
       "  {'word': 'sealed,', 'start': 26.594, 'end': 26.999},\n",
       "  {'word': 'the', 'start': 27.059, 'end': 27.282},\n",
       "  {'word': 'water', 'start': 27.363, 'end': 27.666},\n",
       "  {'word': 'had', 'start': 27.727, 'end': 27.889},\n",
       "  {'word': 'nowhere', 'start': 28.05, 'end': 28.475},\n",
       "  {'word': 'to', 'start': 28.576, 'end': 28.657},\n",
       "  {'word': 'go.', 'start': 28.738, 'end': 28.94},\n",
       "  {'word': 'eventually,', 'start': 29.26, 'end': 29.893},\n",
       "  {'word': 'it', 'start': 30.036, 'end': 30.117},\n",
       "  {'word': 'pooled', 'start': 30.24, 'end': 30.689},\n",
       "  {'word': 'on', 'start': 30.791, 'end': 30.954},\n",
       "  {'word': 'the', 'start': 30.974, 'end': 31.036},\n",
       "  {'word': 'street.', 'start': 31.056, 'end': 31.28}]}"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %%\n",
    "final_response = {\n",
    "    \"verdict\": {\n",
    "        \"fluency_score\": fluency_score,\n",
    "        \"readiness\": readiness,\n",
    "        \"confidence\": 0.92\n",
    "    },\n",
    "\n",
    "    \"benchmarking\": benchmarking,\n",
    "\n",
    "    \"normalized_metrics\": normalized_metrics,\n",
    "\n",
    "    \"opinions\": opinions,\n",
    "\n",
    "    \"word_timestamps\": df_words.to_dict(orient=\"records\"),\n",
    "\n",
    "    \"segment_timestamps\": df_segments.to_dict(orient=\"records\"),\n",
    "\n",
    "    \"filler_events\": df_final_fillers.to_dict(orient=\"records\"),\n",
    "\n",
    "    \"aligned_words\": df_aligned_words.to_dict(orient=\"records\"),\n",
    "}\n",
    "\n",
    "final_response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7baf484",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "speech-analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
