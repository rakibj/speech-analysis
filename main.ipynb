{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "558032e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import whisper\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "pd.set_option(\"display.width\", 0)\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "adfb1d76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total duration (s): 93.46\n",
      "Total words: 183\n",
      "Words per minute: 117.48\n",
      "Unique words: 98\n",
      "Vocabulary richness: 0.54\n"
     ]
    }
   ],
   "source": [
    "audio_file_path = \"sample5.flac\"\n",
    "speech_context = \"conversational\"\n",
    "model = whisper.load_model(\"base\", device=\"cpu\")\n",
    "\n",
    "result = model.transcribe(\n",
    "    audio_file_path,\n",
    "    task=\"transcribe\",\n",
    "    word_timestamps=True,\n",
    "    fp16=False,\n",
    ")\n",
    "words = []\n",
    "for seg in result[\"segments\"]:\n",
    "    for w in seg[\"words\"]:\n",
    "        words.append({\n",
    "            \"word\": w[\"word\"].strip(),\n",
    "            \"start\": float(w[\"start\"]),\n",
    "            \"end\": float(w[\"end\"]),\n",
    "            \"duration\": float(w[\"end\"] - w[\"start\"]),\n",
    "            \"confidence\": float(w[\"probability\"])\n",
    "        })\n",
    "\n",
    "df_words = pd.DataFrame(words)\n",
    "df_words.sort_values(\"confidence\").head(5)\n",
    "\n",
    "segments = []\n",
    "for seg in result[\"segments\"]:\n",
    "    segments.append({\n",
    "        \"text\": seg[\"text\"].strip(),\n",
    "        \"start\": float(seg[\"start\"]),\n",
    "        \"end\": float(seg[\"end\"]),\n",
    "        \"duration\": float(float(seg[\"end\"]) - float(seg[\"start\"])),\n",
    "        \"avg_word_confidence\": sum([float(w[\"probability\"]) for w in seg[\"words\"]]) / (len(seg[\"words\"]) if len(seg[\"words\"]) > 0 else 0.0)\n",
    "    })\n",
    "\n",
    "df_segments = pd.DataFrame(segments)\n",
    "\n",
    "total_duration = float(df_segments.iloc[-1]['end']) #- df_segments.iloc[0]['start'])\n",
    "words_per_minute = (len(df_words) * 60) / (total_duration) \n",
    "\n",
    "\n",
    "\n",
    "pauses = df_words[\"start\"].iloc[1:].values - df_words[\"end\"].iloc[:-1].values\n",
    "long_pauses = pauses[pauses > 1.0]\n",
    "very_long_pauses = pauses[pauses > 2.0]\n",
    "\n",
    "words_clean = df_words['word'].str.lower()\n",
    "words_unique = words_clean.nunique()\n",
    "words_total = len(words_clean)\n",
    "vocab_richness = words_unique / words_total if words_total > 0 else 0\n",
    "top_repeats = words_clean.value_counts().head(5)\n",
    "print(f\"Total duration (s): {total_duration:.2f}\")\n",
    "print(f\"Total words: {words_total}\")\n",
    "print(f\"Words per minute: {words_per_minute:.2f}\")\n",
    "print(f\"Unique words: {words_unique}\")\n",
    "print(f\"Vocabulary richness: {vocab_richness:.2f}\")\n",
    "\n",
    "df_words;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "c6f866e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-large-960h and are newly initialized: ['wav2vec2.masked_spec_embed']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "from transformers import Wav2Vec2Processor, Wav2Vec2ForCTC\n",
    "import soundfile as sf\n",
    "\n",
    "processor = Wav2Vec2Processor.from_pretrained(\"facebook/wav2vec2-large-960h\") #Audio → numbers → shape the model expects\n",
    "wav2vec = Wav2Vec2ForCTC.from_pretrained(\"facebook/wav2vec2-large-960h\") #The model itself\n",
    "wav2vec.eval(); #Set to eval mode (we are not training)\n",
    "\n",
    "waveform, sr = sf.read(audio_file_path, dtype=\"float32\") # waveform: np.ndarray, sr: int, each number in waveform signifies amplitude at that time\n",
    "\n",
    "# Convert stereo → mono\n",
    "if waveform.ndim == 2:\n",
    "    waveform = waveform.mean(axis=1)\n",
    "\n",
    "waveform = torch.from_numpy(waveform) # Convert to torch tensor\n",
    "\n",
    "# Resample to 16kHz if needed (since the model expects 16kHz audio)\n",
    "if sr != 16000:\n",
    "    waveform = torchaudio.functional.resample(waveform, sr, 16000)\n",
    "    sr = 16000\n",
    "\n",
    "# Prepare input for the model\n",
    "inputs = processor(\n",
    "    waveform.squeeze(), # Remove any extra dimensions\n",
    "    sampling_rate=16000,\n",
    "    return_tensors=\"pt\", # Return PyTorch tensors\n",
    ")\n",
    "\n",
    "# Forward pass through the model\n",
    "with torch.no_grad():\n",
    "    logits = wav2vec(**inputs).logits # logit = time_step_1 -> [prob_sound_1, ...]\n",
    "\n",
    "# for each time slice, choose sound with highest probability\n",
    "predicted_ids = torch.argmax(logits, dim=-1)[0]\n",
    "# Convert token IDs to human readable tokens\n",
    "tokens = processor.tokenizer.convert_ids_to_tokens(predicted_ids.tolist()) #tokens # each token is 20ms of audio that represents what was spoken\n",
    "# <pad> = nothing meaningful happened in this 20ms slice\n",
    "# | = word boundary\n",
    "\n",
    "FRAME_SEC = 0.02  # 20 ms per token\n",
    "\n",
    "events = []\n",
    "current = None\n",
    "\n",
    "for i, tok in enumerate(tokens):\n",
    "    t = i * FRAME_SEC\n",
    "\n",
    "    if tok == '<pad>':\n",
    "        if current:\n",
    "            current[\"end\"] = t\n",
    "            events.append(current)\n",
    "            current = None\n",
    "        continue\n",
    "\n",
    "    if current and current[\"label\"] == tok:\n",
    "        # same sound continuing (elongation)\n",
    "        continue\n",
    "\n",
    "    if current:\n",
    "        current[\"end\"] = t\n",
    "        events.append(current)\n",
    "\n",
    "    current = {\n",
    "        \"label\": tok,\n",
    "        \"start\": t\n",
    "    }\n",
    "\n",
    "if current:\n",
    "    current[\"end\"] = t\n",
    "    events.append(current)\n",
    "\n",
    "df_wav2vec = pd.DataFrame(events)\n",
    "\n",
    "df_wav2vec[\"duration\"] = df_wav2vec[\"end\"] - df_wav2vec[\"start\"]\n",
    "df_wav2vec[\"labels\"] = df_wav2vec[\"label\"]\n",
    "\n",
    "\n",
    "merged = []\n",
    "current = None\n",
    "\n",
    "for _, row in df_wav2vec.iterrows():\n",
    "    if current is None:\n",
    "        current = row.to_dict()\n",
    "        continue\n",
    "\n",
    "    if row[\"label\"] == current[\"label\"] and row[\"start\"] <= current[\"end\"] + 0.04:\n",
    "        # same sound, extend it\n",
    "        current[\"end\"] = row[\"end\"]\n",
    "    else:\n",
    "        merged.append(current)\n",
    "        current = row.to_dict()\n",
    "\n",
    "if current:\n",
    "    merged.append(current)\n",
    "\n",
    "df_wav2vec_merged = pd.DataFrame(merged)\n",
    "df_wav2vec_merged[\"duration\"] = (\n",
    "    df_wav2vec_merged[\"end\"] - df_wav2vec_merged[\"start\"]\n",
    ")\n",
    "\n",
    "pauses = []\n",
    "\n",
    "for i in range(1, len(events)):\n",
    "    gap = events[i][\"start\"] - events[i-1][\"end\"]\n",
    "    if gap >= 0.3:  # 300 ms\n",
    "        pauses.append({\n",
    "            \"type\": \"pause\",\n",
    "            \"start\": events[i-1][\"end\"],\n",
    "            \"end\": events[i][\"start\"],\n",
    "            \"duration\": gap\n",
    "        })\n",
    "\n",
    "pauses;\n",
    "\n",
    "\n",
    "import soundfile as sf\n",
    "import torchaudio\n",
    "\n",
    "def load_audio(path):\n",
    "    audio, sr = sf.read(path, dtype=\"float32\")\n",
    "    if audio.ndim == 2:\n",
    "        audio = audio.mean(axis=1)  # stereo → mono\n",
    "    if sr != 16000:\n",
    "        audio = torchaudio.functional.resample(\n",
    "            torch.from_numpy(audio), sr, 16000\n",
    "        ).numpy()\n",
    "        sr = 16000\n",
    "    return audio, sr\n",
    "\n",
    "audio, sr = load_audio(audio_file_path)\n",
    "\n",
    "import whisperx\n",
    "import torch\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "align_model, metadata = whisperx.load_align_model(\n",
    "    language_code=\"en\",  # or result[\"language\"] if available\n",
    "    device=device\n",
    ")\n",
    "\n",
    "aligned = whisperx.align(\n",
    "    result[\"segments\"],  # <-- your existing Whisper output\n",
    "    align_model,\n",
    "    metadata,\n",
    "    audio,\n",
    "    device\n",
    ")\n",
    "\n",
    "aligned_words = []\n",
    "\n",
    "for seg in aligned[\"segments\"]:\n",
    "    for w in seg.get(\"words\", []):\n",
    "        if w[\"start\"] is not None and w[\"end\"] is not None:\n",
    "            aligned_words.append({\n",
    "                \"word\": w[\"word\"].strip().lower(),\n",
    "                \"start\": float(w[\"start\"]),\n",
    "                \"end\": float(w[\"end\"])\n",
    "            })\n",
    "\n",
    "df_aligned_words = pd.DataFrame(aligned_words)\n",
    "df_aligned_words = df_aligned_words.sort_values(\"start\").reset_index(drop=True)\n",
    "# df_aligned_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "896c512f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>style</th>\n",
       "      <th>type</th>\n",
       "      <th>text</th>\n",
       "      <th>raw_label</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>clear</td>\n",
       "      <td>filler</td>\n",
       "      <td>um</td>\n",
       "      <td>um,</td>\n",
       "      <td>18.88</td>\n",
       "      <td>20.06</td>\n",
       "      <td>1.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>subtle</td>\n",
       "      <td>stutter</td>\n",
       "      <td>d</td>\n",
       "      <td>D</td>\n",
       "      <td>24.06</td>\n",
       "      <td>24.08</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>clear</td>\n",
       "      <td>filler</td>\n",
       "      <td>uh</td>\n",
       "      <td>uh,</td>\n",
       "      <td>24.26</td>\n",
       "      <td>24.38</td>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>clear</td>\n",
       "      <td>filler</td>\n",
       "      <td>um</td>\n",
       "      <td>um,</td>\n",
       "      <td>26.00</td>\n",
       "      <td>26.22</td>\n",
       "      <td>0.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>subtle</td>\n",
       "      <td>stutter</td>\n",
       "      <td>b</td>\n",
       "      <td>B</td>\n",
       "      <td>33.74</td>\n",
       "      <td>33.76</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>subtle</td>\n",
       "      <td>stutter</td>\n",
       "      <td>t</td>\n",
       "      <td>T</td>\n",
       "      <td>33.88</td>\n",
       "      <td>33.90</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>subtle</td>\n",
       "      <td>stutter</td>\n",
       "      <td>s</td>\n",
       "      <td>S</td>\n",
       "      <td>33.98</td>\n",
       "      <td>34.00</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>subtle</td>\n",
       "      <td>stutter</td>\n",
       "      <td>s</td>\n",
       "      <td>S</td>\n",
       "      <td>38.70</td>\n",
       "      <td>38.72</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>subtle</td>\n",
       "      <td>stutter</td>\n",
       "      <td>l</td>\n",
       "      <td>L</td>\n",
       "      <td>38.94</td>\n",
       "      <td>38.96</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>subtle</td>\n",
       "      <td>stutter</td>\n",
       "      <td>y</td>\n",
       "      <td>Y</td>\n",
       "      <td>39.06</td>\n",
       "      <td>39.08</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>subtle</td>\n",
       "      <td>stutter</td>\n",
       "      <td>t</td>\n",
       "      <td>T</td>\n",
       "      <td>39.18</td>\n",
       "      <td>39.20</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>subtle</td>\n",
       "      <td>stutter</td>\n",
       "      <td>s</td>\n",
       "      <td>S</td>\n",
       "      <td>43.76</td>\n",
       "      <td>43.78</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>subtle</td>\n",
       "      <td>stutter</td>\n",
       "      <td>t</td>\n",
       "      <td>T</td>\n",
       "      <td>51.68</td>\n",
       "      <td>51.70</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>subtle</td>\n",
       "      <td>stutter</td>\n",
       "      <td>y</td>\n",
       "      <td>Y</td>\n",
       "      <td>51.78</td>\n",
       "      <td>51.80</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>subtle</td>\n",
       "      <td>stutter</td>\n",
       "      <td>t</td>\n",
       "      <td>T</td>\n",
       "      <td>54.88</td>\n",
       "      <td>54.90</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>subtle</td>\n",
       "      <td>stutter</td>\n",
       "      <td>b</td>\n",
       "      <td>B</td>\n",
       "      <td>66.62</td>\n",
       "      <td>66.66</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>subtle</td>\n",
       "      <td>stutter</td>\n",
       "      <td>r</td>\n",
       "      <td>R</td>\n",
       "      <td>68.14</td>\n",
       "      <td>68.16</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>subtle</td>\n",
       "      <td>stutter</td>\n",
       "      <td>r</td>\n",
       "      <td>R</td>\n",
       "      <td>69.32</td>\n",
       "      <td>69.34</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>subtle</td>\n",
       "      <td>stutter</td>\n",
       "      <td>w</td>\n",
       "      <td>W</td>\n",
       "      <td>69.62</td>\n",
       "      <td>69.64</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>subtle</td>\n",
       "      <td>stutter</td>\n",
       "      <td>t</td>\n",
       "      <td>T</td>\n",
       "      <td>69.80</td>\n",
       "      <td>69.82</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>subtle</td>\n",
       "      <td>stutter</td>\n",
       "      <td>d</td>\n",
       "      <td>D</td>\n",
       "      <td>69.90</td>\n",
       "      <td>69.92</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>subtle</td>\n",
       "      <td>stutter</td>\n",
       "      <td>t</td>\n",
       "      <td>T</td>\n",
       "      <td>70.08</td>\n",
       "      <td>70.12</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>subtle</td>\n",
       "      <td>stutter</td>\n",
       "      <td>t</td>\n",
       "      <td>T</td>\n",
       "      <td>73.30</td>\n",
       "      <td>73.32</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>subtle</td>\n",
       "      <td>stutter</td>\n",
       "      <td>t</td>\n",
       "      <td>T</td>\n",
       "      <td>81.40</td>\n",
       "      <td>81.42</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>subtle</td>\n",
       "      <td>stutter</td>\n",
       "      <td>t</td>\n",
       "      <td>T</td>\n",
       "      <td>84.74</td>\n",
       "      <td>84.78</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     style     type text raw_label  start    end  duration\n",
       "0    clear   filler   um       um,  18.88  20.06      1.18\n",
       "1   subtle  stutter    d         D  24.06  24.08      0.02\n",
       "2    clear   filler   uh       uh,  24.26  24.38      0.12\n",
       "3    clear   filler   um       um,  26.00  26.22      0.22\n",
       "4   subtle  stutter    b         B  33.74  33.76      0.02\n",
       "5   subtle  stutter    t         T  33.88  33.90      0.02\n",
       "6   subtle  stutter    s         S  33.98  34.00      0.02\n",
       "7   subtle  stutter    s         S  38.70  38.72      0.02\n",
       "8   subtle  stutter    l         L  38.94  38.96      0.02\n",
       "9   subtle  stutter    y         Y  39.06  39.08      0.02\n",
       "10  subtle  stutter    t         T  39.18  39.20      0.02\n",
       "11  subtle  stutter    s         S  43.76  43.78      0.02\n",
       "12  subtle  stutter    t         T  51.68  51.70      0.02\n",
       "13  subtle  stutter    y         Y  51.78  51.80      0.02\n",
       "14  subtle  stutter    t         T  54.88  54.90      0.02\n",
       "15  subtle  stutter    b         B  66.62  66.66      0.04\n",
       "16  subtle  stutter    r         R  68.14  68.16      0.02\n",
       "17  subtle  stutter    r         R  69.32  69.34      0.02\n",
       "18  subtle  stutter    w         W  69.62  69.64      0.02\n",
       "19  subtle  stutter    t         T  69.80  69.82      0.02\n",
       "20  subtle  stutter    d         D  69.90  69.92      0.02\n",
       "21  subtle  stutter    t         T  70.08  70.12      0.04\n",
       "22  subtle  stutter    t         T  73.30  73.32      0.02\n",
       "23  subtle  stutter    t         T  81.40  81.42      0.02\n",
       "24  subtle  stutter    t         T  84.74  84.78      0.04"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# conservative mapping: only sounds we are confident about\n",
    "FILLER_MAP = {\n",
    "    \"A\": \"uh\",\n",
    "    \"E\": \"uh\",\n",
    "    \"U\": \"uh\",\n",
    "    \"M\": \"um\",\n",
    "    \"N\": \"um\",\n",
    "    \"MM\": \"um\",\n",
    "    \"NN\": \"um\",\n",
    "}\n",
    "STUTTER_CONSONANTS = set(\"BCDFGHJKLPQRSTVWXYZ\")\n",
    "\n",
    "\n",
    "# check overlap of wav2vec events with real words from alignment\n",
    "def overlaps_any_word_relaxed(start, end, words, tol=0.05):\n",
    "    for _, w in words.iterrows():\n",
    "        if start < w[\"end\"] + tol and end > w[\"start\"] - tol:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "\n",
    "\n",
    "df_wav2vec_merged = df_wav2vec_merged.copy()\n",
    "\n",
    "# for each row (axis=1) return the function value and store it in the overlaps_word column\n",
    "df_wav2vec_merged[\"overlaps_word\"] = df_wav2vec_merged.apply(\n",
    "    lambda r: overlaps_any_word_relaxed(\n",
    "        r[\"start\"], r[\"end\"], df_aligned_words\n",
    "    ),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# get rows where overlaps_word is False, that gives non words\n",
    "df_non_word = df_wav2vec_merged.loc[\n",
    "    ~df_wav2vec_merged[\"overlaps_word\"]\n",
    "].copy()\n",
    "\n",
    "\n",
    "# Word-onset suppression to allow 200ms of lead-in to real words\n",
    "WORD_ONSET_SUPPRESSION_MS = 0.2\n",
    "\n",
    "word_starts = df_aligned_words[[\"start\"]].copy()\n",
    "\n",
    "# function to check if a non-word event is within the lead-in time of a real word\n",
    "def is_word_initial_noise(row, word_starts, max_lead=WORD_ONSET_SUPPRESSION_MS):\n",
    "    end = row[\"end\"]\n",
    "\n",
    "    upcoming = word_starts[\n",
    "        (word_starts[\"start\"] >= end) &\n",
    "        ((word_starts[\"start\"] - end) <= max_lead)\n",
    "    ]\n",
    "\n",
    "    return not upcoming.empty\n",
    "\n",
    "# mark non-word events that are word-initial noises\n",
    "df_non_word[\"is_word_initial\"] = df_non_word.apply(\n",
    "    lambda r: (\n",
    "        is_word_initial_noise(r, word_starts)\n",
    "        and r[\"labels\"].upper() in FILLER_MAP\n",
    "    ),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "\n",
    "# Kill fake fillers\n",
    "df_non_word = df_non_word.loc[\n",
    "    ~df_non_word[\"is_word_initial\"]\n",
    "].reset_index(drop=True)\n",
    "\n",
    "\n",
    "\n",
    "def classify_non_word_event(row):\n",
    "    label = row[\"labels\"].upper()\n",
    "    duration = row[\"duration\"]\n",
    "\n",
    "    # normalize elongation\n",
    "    norm = re.sub(r\"(.)\\1+\", r\"\\1\", label)\n",
    "\n",
    "    # ---- FILLERS ----\n",
    "    # Is this sound one of our known filler phonemes, AND is it long enough?\n",
    "    if norm in FILLER_MAP and duration >= 0.08:\n",
    "        return {\n",
    "            \"type\": \"filler\",\n",
    "            \"raw_label\": label,\n",
    "            \"text\": FILLER_MAP[norm],\n",
    "        }\n",
    "\n",
    "    # ---- STUTTERS ----\n",
    "    # Is this sound a alphabetic characer or phrase but not a known filler, AND is it short enough?\n",
    "    if (\n",
    "    label.upper() in STUTTER_CONSONANTS\n",
    "    and norm not in FILLER_MAP\n",
    "    and duration < 0.15\n",
    "    ):\n",
    "        return {\n",
    "            \"type\": \"stutter\",\n",
    "            \"raw_label\": label,\n",
    "            \"text\": norm.lower()\n",
    "        }\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "\n",
    "converted = []\n",
    "\n",
    "for _, row in df_non_word.iterrows():\n",
    "    result = classify_non_word_event(row)\n",
    "    if result:\n",
    "        converted.append({\n",
    "            \"type\": result[\"type\"],\n",
    "            \"text\": result[\"text\"],\n",
    "            \"raw_label\": result[\"raw_label\"],\n",
    "            \"start\": row[\"start\"],\n",
    "            \"end\": row[\"end\"],\n",
    "            \"duration\": row[\"duration\"]\n",
    "        })\n",
    "\n",
    "# Keep all fillers and stutters\n",
    "df_filler_events = pd.DataFrame(converted)\n",
    "df_filler_events.head()\n",
    "\n",
    "\n",
    "\n",
    "# Do a filler check with Whisper verbatim transcription\n",
    "filler_model = whisper.load_model(\"base\", device=\"cpu\")\n",
    "verbatim_result = filler_model.transcribe(\n",
    "    audio_file_path,\n",
    "    task=\"transcribe\",\n",
    "    temperature=0,\n",
    "    word_timestamps=True,\n",
    "    condition_on_previous_text=False,\n",
    "    initial_prompt=(\n",
    "        \"Transcribe verbatim. Include filler words like um, uh, er, \"\n",
    "        \"false starts, repetitions, and hesitations.\"\n",
    "    ),\n",
    "    fp16=False,\n",
    ")\n",
    "\n",
    "import re\n",
    "\n",
    "FILLER_PATTERN = re.compile(\n",
    "    r\"^(um+|uh+|erm+|er+|ah+|eh+)$\",\n",
    "    re.IGNORECASE\n",
    ")\n",
    "\n",
    "def normalize_whisper_token(token: str) -> str:\n",
    "    \"\"\"\n",
    "    Normalize Whisper word tokens like:\n",
    "    'um,' -> 'um'\n",
    "    'uh...' -> 'uh'\n",
    "    'erm-' -> 'erm'\n",
    "    \"\"\"\n",
    "    token = token.lower().strip()\n",
    "\n",
    "    # remove leading/trailing punctuation\n",
    "    token = re.sub(r\"^[^\\w]+|[^\\w]+$\", \"\", token)\n",
    "\n",
    "    return token\n",
    "\n",
    "\n",
    "whisper_fillers = []\n",
    "\n",
    "for seg in verbatim_result.get(\"segments\", []):\n",
    "    for w in seg.get(\"words\", []):\n",
    "        raw = w[\"word\"]\n",
    "        norm = normalize_whisper_token(raw)\n",
    "\n",
    "        if not norm:\n",
    "            continue\n",
    "\n",
    "        if FILLER_PATTERN.match(norm):\n",
    "            whisper_fillers.append({\n",
    "                \"type\": \"filler\",\n",
    "                \"text\": norm,                 # canonical filler\n",
    "                \"raw_text\": raw,              # keep original for debugging\n",
    "                \"start\": float(w[\"start\"]),\n",
    "                \"end\": float(w[\"end\"]),\n",
    "                \"duration\": float(w[\"end\"] - w[\"start\"]),\n",
    "                \"confidence\": float(w[\"probability\"]),\n",
    "            })\n",
    "if whisper_fillers:\n",
    "    df_whisper_fillers = pd.DataFrame(whisper_fillers)\n",
    "\n",
    "else:\n",
    "    df_whisper_fillers = pd.DataFrame(\n",
    "        columns=[\n",
    "            \"type\",\n",
    "            \"text\",\n",
    "            \"raw_text\",\n",
    "            \"start\",\n",
    "            \"end\",\n",
    "            \"duration\",\n",
    "            \"confidence\",\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "\n",
    "\n",
    "def overlaps_time(a_start, a_end, b_start, b_end, tol=0.08):\n",
    "    \"\"\"\n",
    "    Returns True if two time intervals overlap within tolerance.\n",
    "    \"\"\"\n",
    "    return (a_start < b_end + tol) and (a_end > b_start - tol)\n",
    "\n",
    "final_fillers = []\n",
    "\n",
    "FINAL_FILLER_COLUMNS = [\n",
    "    \"style\",\n",
    "    \"type\",\n",
    "    \"text\",\n",
    "    \"raw_label\",\n",
    "    \"start\",\n",
    "    \"end\",\n",
    "    \"duration\",\n",
    "]\n",
    "\n",
    "# 1️⃣ Add Whisper fillers FIRST (explicit, lexical)\n",
    "for _, wf in df_whisper_fillers.iterrows():\n",
    "    final_fillers.append({\n",
    "        \"style\": \"clear\",\n",
    "        \"type\": \"filler\",\n",
    "        \"text\": wf[\"text\"],\n",
    "        \"raw_label\": wf[\"raw_text\"],\n",
    "        \"start\": wf[\"start\"],\n",
    "        \"end\": wf[\"end\"],\n",
    "        \"duration\": wf[\"duration\"],\n",
    "    })\n",
    "\n",
    "# 2️⃣ Add wav2vec fillers/stutters ONLY if they don't overlap Whisper\n",
    "for _, row in df_filler_events.iterrows():\n",
    "    is_duplicate = False\n",
    "\n",
    "    for af in final_fillers:\n",
    "        if overlaps_time(\n",
    "            row[\"start\"], row[\"end\"],\n",
    "            af[\"start\"], af[\"end\"]\n",
    "        ):\n",
    "            is_duplicate = True\n",
    "            break\n",
    "\n",
    "    if not is_duplicate:\n",
    "        final_fillers.append({\n",
    "            \"style\": \"subtle\",\n",
    "            \"type\": row[\"type\"],     # filler OR stutter\n",
    "            \"text\": row[\"text\"],\n",
    "            \"raw_label\": row.get(\"raw_label\", None),\n",
    "            \"start\": row[\"start\"],\n",
    "            \"end\": row[\"end\"],\n",
    "            \"duration\": row[\"duration\"],\n",
    "        })\n",
    "\n",
    "df_final_fillers = pd.DataFrame(\n",
    "    final_fillers,\n",
    "    columns=FINAL_FILLER_COLUMNS\n",
    ")\n",
    "\n",
    "if not df_final_fillers.empty:\n",
    "    df_final_fillers = (\n",
    "        df_final_fillers\n",
    "        .sort_values(\"start\")\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "df_final_fillers\n",
    "#df_whisper_fillers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "c5167103",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>style</th>\n",
       "      <th>type</th>\n",
       "      <th>text</th>\n",
       "      <th>raw_label</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>duration</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>clear</td>\n",
       "      <td>filler</td>\n",
       "      <td>um</td>\n",
       "      <td>um,</td>\n",
       "      <td>18.88</td>\n",
       "      <td>20.06</td>\n",
       "      <td>1.18</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>clear</td>\n",
       "      <td>filler</td>\n",
       "      <td>uh</td>\n",
       "      <td>uh,</td>\n",
       "      <td>24.26</td>\n",
       "      <td>24.38</td>\n",
       "      <td>0.12</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>clear</td>\n",
       "      <td>filler</td>\n",
       "      <td>um</td>\n",
       "      <td>um,</td>\n",
       "      <td>26.00</td>\n",
       "      <td>26.22</td>\n",
       "      <td>0.22</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   style    type text raw_label  start    end  duration  count\n",
       "0  clear  filler   um       um,  18.88  20.06      1.18    NaN\n",
       "1  clear  filler   uh       uh,  24.26  24.38      0.12    NaN\n",
       "2  clear  filler   um       um,  26.00  26.22      0.22    NaN"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_stutters = df_final_fillers[df_final_fillers[\"type\"] == \"stutter\"].copy()\n",
    "df_fillers = df_final_fillers[df_final_fillers[\"type\"] == \"filler\"].copy()\n",
    "\n",
    "GROUP_GAP_SEC = 0.15  # max gap between repetitions\n",
    "\n",
    "grouped = []\n",
    "current = None\n",
    "\n",
    "for _, row in df_stutters.iterrows():\n",
    "    if current is None:\n",
    "        current = row.to_dict()\n",
    "        current[\"count\"] = 1\n",
    "        continue\n",
    "\n",
    "    same_sound = row[\"raw_label\"] == current[\"raw_label\"]\n",
    "    close_in_time = row[\"start\"] - current[\"end\"] <= GROUP_GAP_SEC\n",
    "\n",
    "    if same_sound and close_in_time:\n",
    "        current[\"end\"] = row[\"end\"]\n",
    "        current[\"duration\"] = current[\"end\"] - current[\"start\"]\n",
    "        current[\"count\"] += 1\n",
    "    else:\n",
    "        grouped.append(current)\n",
    "        current = row.to_dict()\n",
    "        current[\"count\"] = 1\n",
    "\n",
    "if current:\n",
    "    grouped.append(current)\n",
    "\n",
    "df_grouped_stutters = pd.DataFrame(grouped)\n",
    "df_grouped_stutters\n",
    "\n",
    "df_final_clean = (\n",
    "    pd.concat([df_fillers, df_grouped_stutters], ignore_index=True)\n",
    "      .sort_values(\"start\")\n",
    "      .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "# --- HARD STUTTER FILTER ---\n",
    "df_final_clean = df_final_clean[\n",
    "    ~(\n",
    "        (df_final_clean[\"type\"] == \"stutter\") &\n",
    "        (df_final_clean[\"count\"].fillna(1) < 2) &\n",
    "        (df_final_clean[\"duration\"] < 0.15)\n",
    "    )\n",
    "].reset_index(drop=True)\n",
    "\n",
    "\n",
    "df_final_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "50cce14e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'wpm': 167.64705882352942,\n",
       " 'fillers_per_min': 0.0,\n",
       " 'stutters_per_min': 0.0,\n",
       " 'long_pauses_per_min': 2.0,\n",
       " 'very_long_pauses_per_min': 0.0,\n",
       " 'pause_time_ratio': np.float64(0.14705882352941171),\n",
       " 'pause_variability': np.float64(0.19539923731433564),\n",
       " 'vocab_richness': 0.8421052631578947,\n",
       " 'repetition_ratio': np.float64(0.07894736842105263)}"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %%\n",
    "# ---------- ENHANCED NORMALIZATION ----------\n",
    "\n",
    "duration_min = max(total_duration / 60.0, 0.5)\n",
    "\n",
    "# Fillers & stutters\n",
    "filler_events = df_final_fillers[df_final_fillers[\"type\"] == \"filler\"]\n",
    "stutter_events = df_final_fillers[df_final_fillers[\"type\"] == \"stutter\"]\n",
    "\n",
    "fillers_per_min = len(filler_events) / duration_min\n",
    "stutters_per_min = len(stutter_events) / duration_min\n",
    "\n",
    "# Pauses\n",
    "pauses = df_words[\"start\"].iloc[1:].values - df_words[\"end\"].iloc[:-1].values\n",
    "long_pauses = pauses[pauses > 1.0]\n",
    "very_long_pauses = pauses[pauses > 2.0]\n",
    "\n",
    "long_pauses_per_min = len(long_pauses) / duration_min\n",
    "very_long_pauses_per_min = len(very_long_pauses) / duration_min\n",
    "pause_time_ratio = pauses[pauses > 0].sum() / total_duration\n",
    "\n",
    "# Lexical\n",
    "words_clean = df_words[\"word\"].str.lower()\n",
    "vocab_richness = words_clean.nunique() / len(words_clean)\n",
    "repetition_ratio = words_clean.value_counts().iloc[0] / len(words_clean)\n",
    "\n",
    "# Temporal fluency instability (variance of gaps)\n",
    "pause_variability = pauses.std() if len(pauses) > 5 else 0.0\n",
    "\n",
    "normalized_metrics = {\n",
    "    \"wpm\": words_per_minute,\n",
    "    \"fillers_per_min\": fillers_per_min,\n",
    "    \"stutters_per_min\": stutters_per_min,\n",
    "    \"long_pauses_per_min\": long_pauses_per_min,\n",
    "    \"very_long_pauses_per_min\": very_long_pauses_per_min,\n",
    "    \"pause_time_ratio\": pause_time_ratio,\n",
    "    \"pause_variability\": pause_variability,\n",
    "    \"vocab_richness\": vocab_richness,\n",
    "    \"repetition_ratio\": repetition_ratio,\n",
    "}\n",
    "\n",
    "normalized_metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "d58fbffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONTEXT_CONFIG = {\n",
    "    \"conversational\": {\n",
    "        \"pause_tolerance\": 1.0,\n",
    "        \"pause_variability_tolerance\": 1.0,\n",
    "    },\n",
    "    \"narrative\": {\n",
    "        \"pause_tolerance\": 1.4,          # allow more long pauses\n",
    "        \"pause_variability_tolerance\": 1.3,\n",
    "    },\n",
    "    \"presentation\": {\n",
    "        \"pause_tolerance\": 1.2,\n",
    "        \"pause_variability_tolerance\": 1.1,\n",
    "    },\n",
    "    \"interview\": {\n",
    "        \"pause_tolerance\": 0.9,          # stricter\n",
    "        \"pause_variability_tolerance\": 0.9,\n",
    "    },\n",
    "}\n",
    "\n",
    "context = CONTEXT_CONFIG.get(speech_context, CONTEXT_CONFIG[\"conversational\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "60d6a570",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %%\n",
    "# ---------- CONSISTENT FLUENCY SCORING ----------\n",
    "\n",
    "import math\n",
    "\n",
    "def clamp01(x):\n",
    "    return max(0.0, min(1.0, x))\n",
    "\n",
    "\n",
    "# ---- Subscores (0–1, higher = better) ----\n",
    "\n",
    "# Speech rate (ASYMMETRIC)\n",
    "wpm = normalized_metrics[\"wpm\"]\n",
    "\n",
    "if wpm < 110:  # too slow hurts fluency hard\n",
    "    speech_rate_score = clamp01((wpm - 70) / 40)\n",
    "elif wpm <= 170:  # optimal band\n",
    "    speech_rate_score = 1.0\n",
    "else:  # too fast hurts gently\n",
    "    speech_rate_score = clamp01(1 - (wpm - 170) / 120)\n",
    "\n",
    "\n",
    "# Pauses (structural)\n",
    "pause_score = clamp01(\n",
    "    1 - (\n",
    "        normalized_metrics[\"long_pauses_per_min\"]\n",
    "        / (4.0 * context[\"pause_tolerance\"])\n",
    "    )\n",
    ")\n",
    "\n",
    "# Fillers (structural)\n",
    "filler_score = clamp01(\n",
    "    1 - (normalized_metrics[\"fillers_per_min\"] / 6.0)\n",
    ")\n",
    "\n",
    "# Stability (structural)\n",
    "stability_score = clamp01(\n",
    "    1 - (\n",
    "        normalized_metrics[\"pause_variability\"]\n",
    "        / (0.7 * context[\"pause_variability_tolerance\"])\n",
    "    )\n",
    ")\n",
    "\n",
    "# Lexical quality (STYLE)\n",
    "lexical_score = clamp01(\n",
    "    0.65 * normalized_metrics[\"vocab_richness\"]\n",
    "    + 0.35 * (1 - normalized_metrics[\"repetition_ratio\"])\n",
    ")\n",
    "\n",
    "\n",
    "# ---- Weighted aggregation ----\n",
    "# Structural dimensions dominate readiness\n",
    "raw_score = (\n",
    "    0.30 * pause_score +\n",
    "    0.25 * filler_score +\n",
    "    0.20 * stability_score +\n",
    "    0.15 * speech_rate_score +\n",
    "    0.10 * lexical_score\n",
    ")\n",
    "\n",
    "fluency_score = int(round(100 * clamp01(raw_score)))\n",
    "fluency_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "eeee627c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'issue': 'hesitation_structure',\n",
       "  'severity': 'high',\n",
       "  'root_cause': 'Pauses frequently interrupt sentence flow.',\n",
       "  'score_impact': 15}]"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %%\n",
    "# ---------- ISSUE DETECTION ----------\n",
    "\n",
    "issues = []\n",
    "\n",
    "def issue(severity, issue_id, root_cause, score_impact):\n",
    "    return {\n",
    "        \"issue\": issue_id,\n",
    "        \"severity\": severity,\n",
    "        \"root_cause\": root_cause,\n",
    "        \"score_impact\": score_impact\n",
    "    }\n",
    "\n",
    "\n",
    "# Structural blockers\n",
    "if pause_score < 0.6:\n",
    "    issues.append(issue(\n",
    "        \"high\",\n",
    "        \"hesitation_structure\",\n",
    "        \"Pauses frequently interrupt sentence flow.\",\n",
    "        int((1 - pause_score) * 30)\n",
    "    ))\n",
    "\n",
    "if filler_score < 0.6:\n",
    "    issues.append(issue(\n",
    "        \"high\",\n",
    "        \"filler_dependency\",\n",
    "        \"Fillers replace silent planning pauses.\",\n",
    "        int((1 - filler_score) * 25)\n",
    "    ))\n",
    "\n",
    "if stability_score < 0.6:\n",
    "    issues.append(issue(\n",
    "        \"medium\",\n",
    "        \"delivery_instability\",\n",
    "        \"Speech rhythm varies unpredictably.\",\n",
    "        int((1 - stability_score) * 20)\n",
    "    ))\n",
    "\n",
    "# Style issues (never blockers alone)\n",
    "if speech_rate_score < 0.7:\n",
    "    issues.append(issue(\n",
    "        \"medium\",\n",
    "        \"delivery_pacing\",\n",
    "        \"Speech rate is faster than optimal for clarity.\",\n",
    "        int((1 - speech_rate_score) * 15)\n",
    "    ))\n",
    "\n",
    "if lexical_score < 0.5:\n",
    "    issues.append(issue(\n",
    "        \"low\",\n",
    "        \"lexical_simplicity\",\n",
    "        \"Frequent reuse of common vocabulary.\",\n",
    "        int((1 - lexical_score) * 10)\n",
    "    ))\n",
    "\n",
    "\n",
    "issues = sorted(issues, key=lambda x: x[\"score_impact\"], reverse=True)\n",
    "issues\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "f0b1848b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'borderline'"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %%\n",
    "# ---------- READINESS JUDGMENT ----------\n",
    "\n",
    "high_issues = [i for i in issues if i[\"severity\"] == \"high\"]\n",
    "medium_issues = [i for i in issues if i[\"severity\"] == \"medium\"]\n",
    "\n",
    "if len(high_issues) >= 2:\n",
    "    readiness = \"not_ready\"\n",
    "elif len(high_issues) == 1:\n",
    "    readiness = \"borderline\"\n",
    "elif len(medium_issues) >= 2:\n",
    "    readiness = \"borderline\"\n",
    "elif fluency_score >= 80:\n",
    "    readiness = \"ready\"\n",
    "else:\n",
    "    readiness = \"borderline\"\n",
    "\n",
    "readiness\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "bc527a35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'percentile': 65,\n",
       " 'target_score': 80,\n",
       " 'score_gap': 2,\n",
       " 'estimated_guided_practice_hours': 1.2}"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %%\n",
    "# ---------- BENCHMARKING ----------\n",
    "\n",
    "# v1 calibrated bands (replace with data later)\n",
    "if fluency_score >= 85:\n",
    "    percentile = 80\n",
    "elif fluency_score >= 75:\n",
    "    percentile = 65\n",
    "elif fluency_score >= 65:\n",
    "    percentile = 50\n",
    "else:\n",
    "    percentile = 30\n",
    "\n",
    "score_gap = (\n",
    "    max(0, 80 - fluency_score)\n",
    "    if readiness != \"ready\"\n",
    "    else 0\n",
    ")\n",
    "\n",
    "benchmarking = {\n",
    "    \"percentile\": percentile,\n",
    "    \"target_score\": 80,\n",
    "    \"score_gap\": score_gap,\n",
    "    \"estimated_guided_practice_hours\": score_gap * 0.6,\n",
    "}\n",
    "\n",
    "\n",
    "benchmarking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "ae7d1e1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'primary_issues': [{'issue': 'hesitation_structure',\n",
       "   'severity': 'high',\n",
       "   'root_cause': 'Pauses frequently interrupt sentence flow.',\n",
       "   'score_impact': 15}],\n",
       " 'action_plan': [{'priority': 1,\n",
       "   'focus': 'hesitation_structure',\n",
       "   'instruction': 'Pause only after completing full clauses.',\n",
       "   'expected_score_gain': 15}]}"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %%\n",
    "# ---------- OPINIONS ----------\n",
    "\n",
    "action_plan = []\n",
    "\n",
    "for idx, issue in enumerate(issues[:3]):\n",
    "    action_plan.append({\n",
    "        \"priority\": idx + 1,\n",
    "        \"focus\": issue[\"issue\"],\n",
    "        \"instruction\": {\n",
    "            \"hesitation_structure\": \"Pause only after completing full clauses.\",\n",
    "            \"filler_dependency\": \"Replace fillers with silent pauses under 300ms.\",\n",
    "            \"delivery_instability\": \"Practice steady pacing with metronome drills.\",\n",
    "            \"delivery_pacing\": \"Reduce speed slightly while maintaining energy.\",\n",
    "            \"lexical_simplicity\": \"Actively substitute repeated words during rehearsal.\"\n",
    "        }[issue[\"issue\"]],\n",
    "        \"expected_score_gain\": issue[\"score_impact\"]\n",
    "    })\n",
    "\n",
    "opinions = {\n",
    "    \"primary_issues\": issues,\n",
    "    \"action_plan\": action_plan\n",
    "}\n",
    "\n",
    "opinions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "f76f4893",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'verdict': {'fluency_score': 78,\n",
       "  'readiness': 'borderline',\n",
       "  'confidence': 0.92},\n",
       " 'benchmarking': {'percentile': 65,\n",
       "  'target_score': 80,\n",
       "  'score_gap': 2,\n",
       "  'estimated_guided_practice_hours': 1.2},\n",
       " 'normalized_metrics': {'wpm': 167.64705882352942,\n",
       "  'fillers_per_min': 0.0,\n",
       "  'stutters_per_min': 0.0,\n",
       "  'long_pauses_per_min': 2.0,\n",
       "  'very_long_pauses_per_min': 0.0,\n",
       "  'pause_time_ratio': np.float64(0.14705882352941171),\n",
       "  'pause_variability': np.float64(0.19539923731433564),\n",
       "  'vocab_richness': 0.8421052631578947,\n",
       "  'repetition_ratio': np.float64(0.07894736842105263)},\n",
       " 'opinions': {'primary_issues': [{'issue': 'hesitation_structure',\n",
       "    'severity': 'high',\n",
       "    'root_cause': 'Pauses frequently interrupt sentence flow.',\n",
       "    'score_impact': 15}],\n",
       "  'action_plan': [{'priority': 1,\n",
       "    'focus': 'hesitation_structure',\n",
       "    'instruction': 'Pause only after completing full clauses.',\n",
       "    'expected_score_gain': 15}]},\n",
       " 'word_timestamps': [{'word': 'Before',\n",
       "   'start': 0.0,\n",
       "   'end': 0.72,\n",
       "   'duration': 0.72,\n",
       "   'confidence': 0.7321627140045166},\n",
       "  {'word': 'he',\n",
       "   'start': 0.72,\n",
       "   'end': 0.92,\n",
       "   'duration': 0.20000000000000007,\n",
       "   'confidence': 0.9906947612762451},\n",
       "  {'word': 'had',\n",
       "   'start': 0.92,\n",
       "   'end': 1.06,\n",
       "   'duration': 0.14,\n",
       "   'confidence': 0.9986252784729004},\n",
       "  {'word': 'time',\n",
       "   'start': 1.06,\n",
       "   'end': 1.3,\n",
       "   'duration': 0.24,\n",
       "   'confidence': 0.9781598448753357},\n",
       "  {'word': 'to',\n",
       "   'start': 1.3,\n",
       "   'end': 1.48,\n",
       "   'duration': 0.17999999999999994,\n",
       "   'confidence': 0.998151957988739},\n",
       "  {'word': 'answer',\n",
       "   'start': 1.48,\n",
       "   'end': 1.82,\n",
       "   'duration': 0.3400000000000001,\n",
       "   'confidence': 0.9979077577590942},\n",
       "  {'word': 'a',\n",
       "   'start': 1.82,\n",
       "   'end': 2.38,\n",
       "   'duration': 0.5599999999999998,\n",
       "   'confidence': 0.7017324566841125},\n",
       "  {'word': 'much',\n",
       "   'start': 2.38,\n",
       "   'end': 2.74,\n",
       "   'duration': 0.3600000000000003,\n",
       "   'confidence': 0.9966304898262024},\n",
       "  {'word': 'encumbered',\n",
       "   'start': 2.74,\n",
       "   'end': 3.5,\n",
       "   'duration': 0.7599999999999998,\n",
       "   'confidence': 0.8770199616750082},\n",
       "  {'word': 'Vera',\n",
       "   'start': 3.5,\n",
       "   'end': 3.72,\n",
       "   'duration': 0.2200000000000002,\n",
       "   'confidence': 0.6637086272239685},\n",
       "  {'word': 'burst',\n",
       "   'start': 3.72,\n",
       "   'end': 4.14,\n",
       "   'duration': 0.4199999999999995,\n",
       "   'confidence': 0.8975229859352112},\n",
       "  {'word': 'into',\n",
       "   'start': 4.14,\n",
       "   'end': 4.4,\n",
       "   'duration': 0.2600000000000007,\n",
       "   'confidence': 0.9911706447601318},\n",
       "  {'word': 'the',\n",
       "   'start': 4.4,\n",
       "   'end': 4.58,\n",
       "   'duration': 0.17999999999999972,\n",
       "   'confidence': 0.9960793852806091},\n",
       "  {'word': 'room',\n",
       "   'start': 4.58,\n",
       "   'end': 4.74,\n",
       "   'duration': 0.16000000000000014,\n",
       "   'confidence': 0.9049587249755859},\n",
       "  {'word': 'with',\n",
       "   'start': 4.74,\n",
       "   'end': 4.92,\n",
       "   'duration': 0.17999999999999972,\n",
       "   'confidence': 0.9947728514671326},\n",
       "  {'word': 'the',\n",
       "   'start': 4.92,\n",
       "   'end': 5.04,\n",
       "   'duration': 0.1200000000000001,\n",
       "   'confidence': 0.9829186201095581},\n",
       "  {'word': 'question,',\n",
       "   'start': 5.04,\n",
       "   'end': 5.34,\n",
       "   'duration': 0.2999999999999998,\n",
       "   'confidence': 0.9954038858413696},\n",
       "  {'word': 'I',\n",
       "   'start': 5.84,\n",
       "   'end': 5.92,\n",
       "   'duration': 0.08000000000000007,\n",
       "   'confidence': 0.7550133466720581},\n",
       "  {'word': 'say,',\n",
       "   'start': 5.92,\n",
       "   'end': 6.12,\n",
       "   'duration': 0.20000000000000018,\n",
       "   'confidence': 0.9299986362457275},\n",
       "  {'word': 'can',\n",
       "   'start': 6.6,\n",
       "   'end': 6.7,\n",
       "   'duration': 0.10000000000000053,\n",
       "   'confidence': 0.24179799854755402},\n",
       "  {'word': 'I',\n",
       "   'start': 6.7,\n",
       "   'end': 6.84,\n",
       "   'duration': 0.13999999999999968,\n",
       "   'confidence': 0.9940977096557617},\n",
       "  {'word': 'leave',\n",
       "   'start': 6.84,\n",
       "   'end': 7.0,\n",
       "   'duration': 0.16000000000000014,\n",
       "   'confidence': 0.9969407916069031},\n",
       "  {'word': 'these',\n",
       "   'start': 7.0,\n",
       "   'end': 7.26,\n",
       "   'duration': 0.2599999999999998,\n",
       "   'confidence': 0.9474289417266846},\n",
       "  {'word': 'here?',\n",
       "   'start': 7.26,\n",
       "   'end': 7.48,\n",
       "   'duration': 0.22000000000000064,\n",
       "   'confidence': 0.9799427390098572},\n",
       "  {'word': 'These',\n",
       "   'start': 8.5,\n",
       "   'end': 9.02,\n",
       "   'duration': 0.5199999999999996,\n",
       "   'confidence': 0.9461628794670105},\n",
       "  {'word': 'were',\n",
       "   'start': 9.02,\n",
       "   'end': 9.54,\n",
       "   'duration': 0.5199999999999996,\n",
       "   'confidence': 0.972228467464447},\n",
       "  {'word': 'a',\n",
       "   'start': 9.54,\n",
       "   'end': 9.64,\n",
       "   'duration': 0.10000000000000142,\n",
       "   'confidence': 0.989799976348877},\n",
       "  {'word': 'small',\n",
       "   'start': 9.64,\n",
       "   'end': 9.96,\n",
       "   'duration': 0.3200000000000003,\n",
       "   'confidence': 0.9973137974739075},\n",
       "  {'word': 'black',\n",
       "   'start': 9.96,\n",
       "   'end': 10.5,\n",
       "   'duration': 0.5399999999999991,\n",
       "   'confidence': 0.7713221311569214},\n",
       "  {'word': 'pig',\n",
       "   'start': 10.5,\n",
       "   'end': 10.78,\n",
       "   'duration': 0.27999999999999936,\n",
       "   'confidence': 0.9876771569252014},\n",
       "  {'word': 'and',\n",
       "   'start': 10.78,\n",
       "   'end': 11.06,\n",
       "   'duration': 0.28000000000000114,\n",
       "   'confidence': 0.4577415883541107},\n",
       "  {'word': 'a',\n",
       "   'start': 11.06,\n",
       "   'end': 11.16,\n",
       "   'duration': 0.09999999999999964,\n",
       "   'confidence': 0.9456689953804016},\n",
       "  {'word': 'lusty',\n",
       "   'start': 11.16,\n",
       "   'end': 11.6,\n",
       "   'duration': 0.4399999999999995,\n",
       "   'confidence': 0.9484487771987915},\n",
       "  {'word': 'specimen',\n",
       "   'start': 11.6,\n",
       "   'end': 12.06,\n",
       "   'duration': 0.46000000000000085,\n",
       "   'confidence': 0.9961948394775391},\n",
       "  {'word': 'of',\n",
       "   'start': 12.06,\n",
       "   'end': 12.26,\n",
       "   'duration': 0.1999999999999993,\n",
       "   'confidence': 0.9951247572898865},\n",
       "  {'word': 'black',\n",
       "   'start': 12.26,\n",
       "   'end': 12.48,\n",
       "   'duration': 0.22000000000000064,\n",
       "   'confidence': 0.8317326903343201},\n",
       "  {'word': 'red',\n",
       "   'start': 12.48,\n",
       "   'end': 12.9,\n",
       "   'duration': 0.41999999999999993,\n",
       "   'confidence': 0.650255024433136},\n",
       "  {'word': 'gamecock.',\n",
       "   'start': 12.9,\n",
       "   'end': 13.6,\n",
       "   'duration': 0.6999999999999993,\n",
       "   'confidence': 0.6920707523822784}],\n",
       " 'segment_timestamps': [{'text': 'Before he had time to answer a much encumbered Vera burst into the room with the question,',\n",
       "   'start': 0.0,\n",
       "   'end': 5.34,\n",
       "   'duration': 5.34,\n",
       "   'avg_word_confidence': 0.9233894675385719},\n",
       "  {'text': 'I say, can I leave these here?',\n",
       "   'start': 5.84,\n",
       "   'end': 7.48,\n",
       "   'duration': 1.6400000000000006,\n",
       "   'avg_word_confidence': 0.8350314519235066},\n",
       "  {'text': 'These were a small black pig and a lusty specimen of black red gamecock.',\n",
       "   'start': 8.5,\n",
       "   'end': 13.6,\n",
       "   'duration': 5.1,\n",
       "   'avg_word_confidence': 0.8701244166919163}],\n",
       " 'filler_events': [],\n",
       " 'aligned_words': [{'word': 'before', 'start': 0.0, 'end': 0.806},\n",
       "  {'word': 'he', 'start': 0.866, 'end': 0.927},\n",
       "  {'word': 'had', 'start': 0.987, 'end': 1.128},\n",
       "  {'word': 'time', 'start': 1.189, 'end': 1.39},\n",
       "  {'word': 'to', 'start': 1.431, 'end': 1.491},\n",
       "  {'word': 'answer', 'start': 1.652, 'end': 1.934},\n",
       "  {'word': 'a', 'start': 1.955, 'end': 1.975},\n",
       "  {'word': 'much', 'start': 2.539, 'end': 2.761},\n",
       "  {'word': 'encumbered', 'start': 2.922, 'end': 3.446},\n",
       "  {'word': 'vera', 'start': 3.506, 'end': 3.889},\n",
       "  {'word': 'burst', 'start': 3.909, 'end': 4.312},\n",
       "  {'word': 'into', 'start': 4.373, 'end': 4.534},\n",
       "  {'word': 'the', 'start': 4.554, 'end': 4.635},\n",
       "  {'word': 'room', 'start': 4.675, 'end': 4.836},\n",
       "  {'word': 'with', 'start': 4.897, 'end': 4.997},\n",
       "  {'word': 'the', 'start': 5.038, 'end': 5.098},\n",
       "  {'word': 'question,', 'start': 5.118, 'end': 5.36},\n",
       "  {'word': 'i', 'start': 5.84, 'end': 5.963},\n",
       "  {'word': 'say,', 'start': 6.024, 'end': 6.209},\n",
       "  {'word': 'can', 'start': 6.66, 'end': 6.783},\n",
       "  {'word': 'i', 'start': 6.844, 'end': 6.886},\n",
       "  {'word': 'leave', 'start': 6.947, 'end': 7.111},\n",
       "  {'word': 'these', 'start': 7.152, 'end': 7.316},\n",
       "  {'word': 'here?', 'start': 7.378, 'end': 7.501},\n",
       "  {'word': 'these', 'start': 8.5, 'end': 9.024},\n",
       "  {'word': 'were', 'start': 9.064, 'end': 9.589},\n",
       "  {'word': 'a', 'start': 9.649, 'end': 9.669},\n",
       "  {'word': 'small', 'start': 9.73, 'end': 10.113},\n",
       "  {'word': 'black', 'start': 10.213, 'end': 10.536},\n",
       "  {'word': 'pig', 'start': 10.657, 'end': 11.0},\n",
       "  {'word': 'and', 'start': 11.06, 'end': 11.121},\n",
       "  {'word': 'a', 'start': 11.181, 'end': 11.201},\n",
       "  {'word': 'lusty', 'start': 11.282, 'end': 11.665},\n",
       "  {'word': 'specimen', 'start': 11.725, 'end': 12.189},\n",
       "  {'word': 'of', 'start': 12.229, 'end': 12.27},\n",
       "  {'word': 'black', 'start': 12.31, 'end': 12.653},\n",
       "  {'word': 'red', 'start': 12.753, 'end': 12.995},\n",
       "  {'word': 'gamecock.', 'start': 13.096, 'end': 13.62}]}"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %%\n",
    "final_response = {\n",
    "    \"verdict\": {\n",
    "        \"fluency_score\": fluency_score,\n",
    "        \"readiness\": readiness,\n",
    "        \"confidence\": 0.92\n",
    "    },\n",
    "\n",
    "    \"benchmarking\": benchmarking,\n",
    "\n",
    "    \"normalized_metrics\": normalized_metrics,\n",
    "\n",
    "    \"opinions\": opinions,\n",
    "\n",
    "    \"word_timestamps\": df_words.to_dict(orient=\"records\"),\n",
    "\n",
    "    \"segment_timestamps\": df_segments.to_dict(orient=\"records\"),\n",
    "\n",
    "    \"filler_events\": df_final_fillers.to_dict(orient=\"records\"),\n",
    "\n",
    "    \"aligned_words\": df_aligned_words.to_dict(orient=\"records\"),\n",
    "}\n",
    "\n",
    "final_response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7baf484",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "speech-analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
