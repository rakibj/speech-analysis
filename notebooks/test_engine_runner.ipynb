{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b449236",
   "metadata": {},
   "source": [
    "## Section 9: Summary and Next Steps\n",
    "\n",
    "### Test Results Summary\n",
    "\n",
    "- ‚úÖ **Basic analysis**: engine runs without LLM\n",
    "- ‚úÖ **Results display**: all output fields accessible\n",
    "- ‚úÖ **Context testing**: multiple contexts work correctly\n",
    "- ‚úÖ **Error handling**: invalid inputs caught properly\n",
    "- ‚úÖ **JSON export**: results saved to file\n",
    "- ‚úÖ **Sync wrapper**: synchronous version works\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "1. **Production Integration**\n",
    "   - Integrate `run_engine()` into your web API or application\n",
    "   - Add appropriate error handling and logging\n",
    "\n",
    "2. **Performance Optimization**\n",
    "   - Monitor analysis time for different audio lengths\n",
    "   - Consider caching or batching for multiple files\n",
    "\n",
    "3. **LLM Testing**\n",
    "   - Enable `use_llm=True` for more accurate semantic analysis\n",
    "   - Budget 60-120 seconds per file with LLM enabled\n",
    "\n",
    "4. **Multiple Audio Files**\n",
    "   - Test with various audio formats (WAV, MP3, etc.)\n",
    "   - Verify handling of different audio qualities\n",
    "\n",
    "### Useful Links\n",
    "\n",
    "- Main implementation: `src/engine.py`\n",
    "- Runner implementation: `src/engine_runner.py`\n",
    "- Documentation: `IMPLEMENTATION_GUIDE.md`\n",
    "- Quick test script: `test_quick.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "399a6932",
   "metadata": {},
   "outputs": [],
   "source": [
    "if audio_bytes:\n",
    "    print(\"Testing synchronous wrapper function...\\n\")\n",
    "    \n",
    "    try:\n",
    "        print(\"üîÑ Running run_engine_sync()...\")\n",
    "        sync_result = run_engine_sync(\n",
    "            audio_bytes=audio_bytes,\n",
    "            context=\"conversational\",\n",
    "            use_llm=False,\n",
    "            filename=selected_audio_file.name\n",
    "        )\n",
    "        \n",
    "        print(f\"‚úì Sync test completed\")\n",
    "        print(f\"  Overall band: {sync_result['band_scores']['overall_band']}\")\n",
    "        print(f\"  Transcript length: {len(sync_result['transcript'])} chars\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "else:\n",
    "    print(\"‚ùå No audio loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "490d9d69",
   "metadata": {},
   "source": [
    "## Section 8: Synchronous Test (run_engine_sync)\n",
    "\n",
    "Test the synchronous wrapper function which doesn't require async/await"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54fdabf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if analysis_result:\n",
    "    # Create output directory\n",
    "    output_dir = PROJECT_ROOT / \"outputs\" / \"notebook_tests\"\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Create filename\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    output_file = output_dir / f\"engine_test_{timestamp}.json\"\n",
    "    \n",
    "    # Save results\n",
    "    with open(output_file, 'w', encoding='utf-8') as f:\n",
    "        json.dump(analysis_result, f, indent=2, ensure_ascii=False)\n",
    "    \n",
    "    print(f\"‚úì Results exported to: {output_file}\")\n",
    "    print(f\"  File size: {output_file.stat().st_size / 1024:.2f} KB\")\n",
    "else:\n",
    "    print(\"‚ùå No results to export\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e95fec06",
   "metadata": {},
   "source": [
    "## Section 7: Export Results to JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2223565",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Testing error handling scenarios...\\n\")\n",
    "\n",
    "# Test 1: Empty audio bytes\n",
    "print(\"Test 1: Empty audio bytes\")\n",
    "try:\n",
    "    result = await run_engine(audio_bytes=b\"\", context=\"conversational\")\n",
    "    print(\"‚ùå Should have raised ValueError\")\n",
    "except ValueError as e:\n",
    "    print(f\"‚úì Correctly caught ValueError: {str(e)}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚úì Caught exception: {type(e).__name__}: {str(e)}\")\n",
    "\n",
    "print()\n",
    "\n",
    "# Test 2: Invalid audio data\n",
    "print(\"Test 2: Invalid audio data\")\n",
    "try:\n",
    "    result = await run_engine(\n",
    "        audio_bytes=b\"\\x00\\x01\\x02\\x03\\x04\\x05\",\n",
    "        context=\"conversational\"\n",
    "    )\n",
    "    print(\"‚ùå Should have raised error for invalid audio\")\n",
    "except Exception as e:\n",
    "    print(f\"‚úì Correctly caught error: {type(e).__name__}\")\n",
    "\n",
    "print()\n",
    "\n",
    "# Test 3: Invalid context\n",
    "print(\"Test 3: Invalid context\")\n",
    "if audio_bytes:\n",
    "    try:\n",
    "        result = await run_engine(\n",
    "            audio_bytes=audio_bytes,\n",
    "            context=\"invalid_context\"  # Not a standard context\n",
    "        )\n",
    "        print(\"‚úì Accepted invalid context (may be handled gracefully)\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚úì Caught error: {type(e).__name__}\")\n",
    "else:\n",
    "    print(\"‚äò Skipped (no audio loaded)\")\n",
    "\n",
    "print(\"\\n‚úì Error handling tests complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "874be19f",
   "metadata": {},
   "source": [
    "## Section 6: Test Error Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a179de2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if audio_bytes:\n",
    "    contexts = [\"conversational\", \"narrative\", \"presentation\"]\n",
    "    context_results = {}\n",
    "    \n",
    "    print(\"Testing different speech contexts...\\n\")\n",
    "    \n",
    "    for ctx in contexts:\n",
    "        try:\n",
    "            print(f\"üîÑ Testing context: {ctx}...\")\n",
    "            result = await run_engine(\n",
    "                audio_bytes=audio_bytes,\n",
    "                context=ctx,\n",
    "                use_llm=False\n",
    "            )\n",
    "            context_results[ctx] = result['band_scores']['overall_band']\n",
    "            print(f\"   Band score: {result['band_scores']['overall_band']}\\n\")\n",
    "        except Exception as e:\n",
    "            print(f\"   ‚ùå Error: {str(e)}\\n\")\n",
    "    \n",
    "    # Compare results\n",
    "    print(\"\\nüìä CONTEXT COMPARISON:\")\n",
    "    print(\"-\" * 40)\n",
    "    for ctx, band in context_results.items():\n",
    "        print(f\"{ctx:20s}: {band}\")\n",
    "else:\n",
    "    print(\"‚ùå No audio loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc939be",
   "metadata": {},
   "source": [
    "## Section 5: Test with Different Contexts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04163882",
   "metadata": {},
   "outputs": [],
   "source": [
    "if analysis_result:\n",
    "    print(\"=\"*70)\n",
    "    print(\"ANALYSIS RESULTS\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # 1. TRANSCRIPT\n",
    "    print(\"\\nüìù TRANSCRIPT:\")\n",
    "    transcript = analysis_result['transcript']\n",
    "    print(f\"{transcript}\\n\")\n",
    "    \n",
    "    # 2. BAND SCORES\n",
    "    print(f\"üéØ IELTS BAND SCORES:\")\n",
    "    overall = analysis_result['band_scores']['overall_band']\n",
    "    print(f\"   Overall Band: {overall}\")\n",
    "    \n",
    "    print(f\"\\n   Criterion Bands:\")\n",
    "    for criterion, band in analysis_result['band_scores']['criterion_bands'].items():\n",
    "        print(f\"     ‚Ä¢ {criterion}: {band}\")\n",
    "    \n",
    "    # 3. METADATA\n",
    "    print(f\"\\n‚è±Ô∏è  METADATA:\")\n",
    "    meta = analysis_result['metadata']\n",
    "    print(f\"   Duration: {meta['audio_duration_sec']}s\")\n",
    "    print(f\"   Speaking time: {meta['speaking_time_sec']}s\")\n",
    "    print(f\"   Total words: {meta['total_words_transcribed']}\")\n",
    "    print(f\"   Content words: {meta['content_word_count']}\")\n",
    "    \n",
    "    # 4. STATISTICS\n",
    "    print(f\"\\nüìä STATISTICS:\")\n",
    "    stats = analysis_result['statistics']\n",
    "    print(f\"   Words transcribed: {stats['total_words_transcribed']}\")\n",
    "    print(f\"   Content words: {stats['content_words']}\")\n",
    "    print(f\"   Filler words: {stats['filler_words_detected']}\")\n",
    "    print(f\"   Filler %: {stats['filler_percentage']}%\")\n",
    "    print(f\"   Monotone: {'Yes' if stats['is_monotone'] else 'No'}\")\n",
    "    \n",
    "    # 5. FLUENCY ANALYSIS\n",
    "    fluency = analysis_result['fluency_analysis']\n",
    "    if fluency:\n",
    "        print(f\"\\n‚ö° FLUENCY METRICS:\")\n",
    "        for key, value in fluency.items():\n",
    "            if isinstance(value, float):\n",
    "                print(f\"   ‚Ä¢ {key}: {value:.3f}\")\n",
    "            else:\n",
    "                print(f\"   ‚Ä¢ {key}: {value}\")\n",
    "    \n",
    "    # 6. PRONUNCIATION\n",
    "    print(f\"\\nüîä PRONUNCIATION:\")\n",
    "    pronun = analysis_result['pronunciation']\n",
    "    intel = pronun['intelligibility']\n",
    "    print(f\"   Mean word confidence: {intel['mean_word_confidence']:.3f}\")\n",
    "    print(f\"   Low confidence ratio: {intel['low_confidence_ratio']:.3f}\")\n",
    "    print(f\"   Monotone detected: {pronun['prosody']['monotone_detected']}\")\n",
    "    \n",
    "    # 7. FEEDBACK\n",
    "    if analysis_result['band_scores']['feedback']:\n",
    "        print(f\"\\nüí¨ FEEDBACK:\")\n",
    "        feedback = analysis_result['band_scores']['feedback']\n",
    "        for criterion, text in feedback.items():\n",
    "            print(f\"\\n   {criterion}:\")\n",
    "            print(f\"   {text}\")\n",
    "    \n",
    "    print(f\"\\n{'='*70}\")\n",
    "else:\n",
    "    print(\"‚ùå No analysis results to display\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aa8a3a4",
   "metadata": {},
   "source": [
    "## Section 4: Display Analysis Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b71e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "if audio_bytes:\n",
    "    print(\"üöÄ Starting analysis (LLM disabled for speed)...\\n\")\n",
    "    \n",
    "    try:\n",
    "        # Run analysis\n",
    "        result = await run_engine(\n",
    "            audio_bytes=audio_bytes,\n",
    "            context=\"conversational\",\n",
    "            device=\"cpu\",\n",
    "            use_llm=False,  # Faster for testing\n",
    "            filename=selected_audio_file.name\n",
    "        )\n",
    "        \n",
    "        # Store result for later\n",
    "        analysis_result = result\n",
    "        \n",
    "        print(\"\\n‚úì Analysis completed successfully!\\n\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå Error: {str(e)}\")\n",
    "        analysis_result = None\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "else:\n",
    "    print(\"‚ùå No audio loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dd8b7f9",
   "metadata": {},
   "source": [
    "## Section 3: Test run_engine() - Basic (No LLM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43eb21d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find and load sample audio\n",
    "data_dir = PROJECT_ROOT / \"data\" / \"ielts_part_2\"\n",
    "\n",
    "if not data_dir.exists():\n",
    "    print(f\"‚ùå Data directory not found: {data_dir}\")\n",
    "else:\n",
    "    audio_files = sorted(data_dir.glob(\"*.wav\"))\n",
    "    print(f\"üìÅ Found {len(audio_files)} audio files in {data_dir}\")\n",
    "    \n",
    "    if audio_files:\n",
    "        # Load first audio file\n",
    "        audio_file = audio_files[0]\n",
    "        print(f\"\\nüìÇ Selected: {audio_file.name}\")\n",
    "        print(f\"   Size: {audio_file.stat().st_size / 1024 / 1024:.2f} MB\")\n",
    "        \n",
    "        # Read audio bytes\n",
    "        with open(audio_file, \"rb\") as f:\n",
    "            audio_bytes = f.read()\n",
    "        \n",
    "        print(f\"   Loaded: {len(audio_bytes)} bytes\")\n",
    "        \n",
    "        # Store for later use\n",
    "        selected_audio_file = audio_file\n",
    "        print(\"\\n‚úì Audio loaded successfully\")\n",
    "    else:\n",
    "        print(\"‚ùå No audio files found\")\n",
    "        selected_audio_file = None\n",
    "        audio_bytes = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "451a2123",
   "metadata": {},
   "source": [
    "## Section 2: Load Sample Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "955b7076",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import sys\n",
    "import json\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "# Add project root to path\n",
    "PROJECT_ROOT = Path.cwd().parent\n",
    "sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "# Import engine runner\n",
    "from src.engine_runner import run_engine, run_engine_sync\n",
    "from src.logging_config import setup_logging\n",
    "\n",
    "# Setup logging\n",
    "logger = setup_logging(level=\"INFO\")\n",
    "\n",
    "print(\"‚úì Imports successful\")\n",
    "print(f\"Project root: {PROJECT_ROOT}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e19a55d8",
   "metadata": {},
   "source": [
    "## Section 1: Import Required Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a536c7a",
   "metadata": {},
   "source": [
    "# Engine Runner Testing Notebook\n",
    "\n",
    "Comprehensive testing notebook for `src/engine_runner.py`\n",
    "\n",
    "This notebook demonstrates:\n",
    "- Loading audio bytes from files\n",
    "- Running the `run_engine()` function\n",
    "- Processing and displaying results\n",
    "- Testing different configurations"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
