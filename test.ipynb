{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "558032e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import whisper\n",
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "from typing import List\n",
    "from pydantic import BaseModel\n",
    "from openai import OpenAI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5177df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "pd.set_option(\"display.width\", 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "085294c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = whisper.load_model(\"base\", device=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "adfb1d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model.transcribe(\"sample2.flac\", word_timestamps=True, fp16=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8386e43a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>duration</th>\n",
       "      <th>confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>can</td>\n",
       "      <td>6.60</td>\n",
       "      <td>6.70</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.241798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>and</td>\n",
       "      <td>10.78</td>\n",
       "      <td>11.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.457742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>red</td>\n",
       "      <td>12.48</td>\n",
       "      <td>12.90</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.650255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Vera</td>\n",
       "      <td>3.50</td>\n",
       "      <td>3.72</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.663709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>gamecock.</td>\n",
       "      <td>12.90</td>\n",
       "      <td>13.60</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.692071</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         word  start    end  duration  confidence\n",
       "19        can   6.60   6.70      0.10    0.241798\n",
       "30        and  10.78  11.06      0.28    0.457742\n",
       "36        red  12.48  12.90      0.42    0.650255\n",
       "9        Vera   3.50   3.72      0.22    0.663709\n",
       "37  gamecock.  12.90  13.60      0.70    0.692071"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = []\n",
    "for seg in result[\"segments\"]:\n",
    "    for w in seg[\"words\"]:\n",
    "        words.append({\n",
    "            \"word\": w[\"word\"].strip(),\n",
    "            \"start\": float(w[\"start\"]),\n",
    "            \"end\": float(w[\"end\"]),\n",
    "            \"duration\": float(w[\"end\"] - w[\"start\"]),\n",
    "            \"confidence\": float(w[\"probability\"])\n",
    "        })\n",
    "\n",
    "df_words = pd.DataFrame(words)\n",
    "df_words.sort_values(\"confidence\").head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "585101d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                         text  \\\n",
      "0  Before he had time to answer a much encumbered Vera burst into the room with the question,   \n",
      "1                                                              I say, can I leave these here?   \n",
      "2                    These were a small black pig and a lusty specimen of black red gamecock.   \n",
      "\n",
      "   start    end  duration  avg_word_confidence  \n",
      "0   0.00   5.34      5.34             0.923389  \n",
      "1   5.84   7.48      1.64             0.835031  \n",
      "2   8.50  13.60      5.10             0.870124  \n"
     ]
    }
   ],
   "source": [
    "segments = []\n",
    "for seg in result[\"segments\"]:\n",
    "    segments.append({\n",
    "        \"text\": seg[\"text\"].strip(),\n",
    "        \"start\": float(seg[\"start\"]),\n",
    "        \"end\": float(seg[\"end\"]),\n",
    "        \"duration\": float(float(seg[\"end\"]) - float(seg[\"start\"])),\n",
    "        \"avg_word_confidence\": sum([float(w[\"probability\"]) for w in seg[\"words\"]]) / (len(seg[\"words\"]) if len(seg[\"words\"]) > 0 else 0.0)\n",
    "    })\n",
    "\n",
    "df_segments = pd.DataFrame(segments)\n",
    "with pd.option_context('display.max_colwidth', None):\n",
    "    print(df_segments.head()) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd0ba46",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6ee5d112",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total duration (s): 13.60\n",
      "Number of words: 38\n",
      "Words per minute: 167.65\n"
     ]
    }
   ],
   "source": [
    "total_duration = float(df_segments.iloc[-1]['end']) #- df_segments.iloc[0]['start'])\n",
    "words_per_minute = (len(df_words) * 60) / (total_duration) \n",
    "\n",
    "print(f\"Total duration (s): {total_duration:.2f}\")\n",
    "print(f\"Number of words: {len(df_words)}\")\n",
    "print(f\"Words per minute: {words_per_minute:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "61da4617",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "       0.  , 0.  , 0.  , 0.  , 0.  , 0.5 , 0.  , 0.48, 0.  , 0.  , 0.  ,\n",
       "       0.  , 1.02, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "       0.  , 0.  , 0.  , 0.  ])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pauses = df_words[\"start\"].iloc[1:].values - df_words[\"end\"].iloc[:-1].values\n",
    "long_pauses = pauses[pauses > 1.0]\n",
    "very_long_pauses = pauses[pauses > 2.0]\n",
    "pauses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "f60af679",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total words: 38\n",
      "Unique words: 32\n",
      "Vocabulary richness: 0.84\n"
     ]
    }
   ],
   "source": [
    "words_clean = df_words['word'].str.lower()\n",
    "words_unique = words_clean.nunique()\n",
    "words_total = len(words_clean)\n",
    "vocab_richness = words_unique / words_total if words_total > 0 else 0\n",
    "top_repeats = words_clean.value_counts().head(5)\n",
    "print(f\"Total words: {words_total}\")\n",
    "print(f\"Unique words: {words_unique}\")\n",
    "print(f\"Vocabulary richness: {vocab_richness:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "58c82900",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRANSCRIPT = \"\"\"\\\n",
    "Iâ€™d like to about a person I really admire, and that is my elder.\n",
    "\n",
    "Sheâ€™s about five years older than me, and Iâ€™ve know her my whole life, obviously, but we became much closer when I was in high school. That was the time when I was quite confused about my future, and she was already working, so I used to talk to her a lot.\n",
    "\n",
    "One I really admire in her is her sense of responsibility. No matter how tired she is, she always finishes what she starts. Sheâ€™s also very calm, which is the complete opposite of me. When thereâ€™s a problem, she doesnâ€™t panic; instead, she tries to find a practical solution. I think thatâ€™s a very useful skill in real life.\n",
    "\n",
    "Another thing I admire is that sheâ€™s very independent. She moved to another city for her and managed everything on her own, from rent to finances, without complaining much. Watching her made me realize that being independent isnâ€™t easy, but itâ€™s definitely worth it.\n",
    "\n",
    "I admire her mainly because she motivates me without forcing me. She never lectures me, but her actions push me to work harder and be more disciplined. Honestly, whenever I feel lazy, I just think about how she handles her life, and that gives me a reality check.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "2e7a5197",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_text = TRANSCRIPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "72647861",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "You are an expert grammar analysis engine specialized in spoken English assessment.\n",
    "\n",
    "Your task:\n",
    "- Analyze the transcript as natural spoken English.\n",
    "- Detect grammatical errors that would be penalized in formal spoken English evaluation (e.g. IELTS Speaking).\n",
    "- Identify errors precisely and conservatively.\n",
    "\n",
    "Error categories:\n",
    "- tense\n",
    "- agreement\n",
    "- articles\n",
    "- prepositions\n",
    "- sentence_structure\n",
    "- other\n",
    "\n",
    "Rules:\n",
    "- Ignore pronunciation issues.\n",
    "- Ignore vocabulary choice unless grammatically incorrect.\n",
    "- Do NOT correct the text.\n",
    "- Do NOT suggest fixes.\n",
    "- Do NOT explain grammar rules.\n",
    "- Do NOT infer intended meaning beyond what is grammatically present.\n",
    "- Treat omissions (missing required words or structures) as grammatical errors.\n",
    "- Count each distinct grammatical error once.\n",
    "\n",
    "For each detected error:\n",
    "- Provide the minimal text span that contains the error.\n",
    "- Include the sentence index (0-based).\n",
    "- Include character start and end positions relative to the full transcript.\n",
    "- Do NOT include corrections or explanations.\n",
    "\n",
    "Analysis steps:\n",
    "1. Determine total sentence count (spoken-style sentences included).\n",
    "2. Identify all grammatical errors.\n",
    "3. Classify each error by type.\n",
    "4. Ensure counts match the listed errors.\n",
    "\n",
    "Return STRICT JSON using EXACTLY this schema:\n",
    "\n",
    "{\n",
    "  \"sentence_count\": number,\n",
    "  \"error_count\": number,\n",
    "  \"errors_by_type\": {\n",
    "    \"tense\": number,\n",
    "    \"agreement\": number,\n",
    "    \"articles\": number,\n",
    "    \"prepositions\": number,\n",
    "    \"sentence_structure\": number,\n",
    "    \"other\": number\n",
    "  },\n",
    "  \"errors\": [\n",
    "    {\n",
    "      \"type\": string,\n",
    "      \"context\": string,\n",
    "      \"sentence_index\": number,\n",
    "      \"char_start\": number,\n",
    "      \"char_end\": number\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "\n",
    "If no grammatical errors are present, return zero counts and an empty errors array.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "98e6fb42",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GrammarError(BaseModel):\n",
    "    type: str\n",
    "    context: str\n",
    "    sentence_index: int\n",
    "    char_start: int\n",
    "    char_end: int\n",
    "\n",
    "\n",
    "class ErrorsByType(BaseModel):\n",
    "    tense: int\n",
    "    agreement: int\n",
    "    articles: int\n",
    "    prepositions: int\n",
    "    sentence_structure: int\n",
    "    other: int\n",
    "\n",
    "\n",
    "class GrammarAnalysis(BaseModel):\n",
    "    sentence_count: int\n",
    "    error_count: int\n",
    "    errors_by_type: ErrorsByType\n",
    "    errors: List[GrammarError]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "f955b4b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "# response = client.responses.create(\n",
    "#     model=\"o4-mini\",\n",
    "#     input=[\n",
    "#         {\n",
    "#             \"role\": \"system\",\n",
    "#             \"content\": \n",
    "#     system_prompt\n",
    "#         },\n",
    "#         {\n",
    "#             \"role\": \"user\",\n",
    "#             \"content\": prompt_text\n",
    "#         }\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "response = client.responses.parse(\n",
    "    model=\"gpt-4o-mini\",  # REQUIRED for Structured Outputs\n",
    "    input=[\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": prompt_text},\n",
    "    ],\n",
    "    text_format=GrammarAnalysis,  # ðŸ”’ schema enforced here\n",
    ")\n",
    "\n",
    "grammar_data: GrammarAnalysis = response.output_parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "67bb88d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tense Iâ€™ve know her my whole life\n",
      "agreement One I really admire in her\n",
      "articles to another city for her\n",
      "articles sheâ€™s the complete opposite of me\n",
      "prepositions watching her made me realize that being independent isnâ€™t easy\n"
     ]
    }
   ],
   "source": [
    "for err in grammar_data.errors:\n",
    "    print(err.type, err.context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b62fcfe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "speech-analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
